[
  {
    "objectID": "posts/2022-03-10-manim.html",
    "href": "posts/2022-03-10-manim.html",
    "title": "manimのメモ",
    "section": "",
    "text": "fileを作成したら以下のコマンドでmp4が作成できる.\nmanim scene.py\nsceneが複数ある場合は選べる.\n次のように指定もできる.\nmanim scene.py CreateCircle\nオプションも存在する.\nmanim -pql scene.py CreateCircle\n-pはplay, -qlはlow quality, -qhはhigh quality, -sは最後のframeをpngで出すオプション.\n\n\n\nfrom manim import *\n\nclass LaTeXTemplateLibrary(Scene):\n    def construct(self):\n        tex = Tex('Hello 你好 \\\\LaTeX 日本語でおk', tex_template=TexTemplateLibrary.ctex, font_size=144)\n        self.add(tex)"
  },
  {
    "objectID": "posts/2022-03-10-manim.html#実行方法",
    "href": "posts/2022-03-10-manim.html#実行方法",
    "title": "manimのメモ",
    "section": "",
    "text": "fileを作成したら以下のコマンドでmp4が作成できる.\nmanim scene.py\nsceneが複数ある場合は選べる.\n次のように指定もできる.\nmanim scene.py CreateCircle\nオプションも存在する.\nmanim -pql scene.py CreateCircle\n-pはplay, -qlはlow quality, -qhはhigh quality, -sは最後のframeをpngで出すオプション."
  },
  {
    "objectID": "posts/2022-03-10-manim.html#texで日本語を使う方法",
    "href": "posts/2022-03-10-manim.html#texで日本語を使う方法",
    "title": "manimのメモ",
    "section": "",
    "text": "from manim import *\n\nclass LaTeXTemplateLibrary(Scene):\n    def construct(self):\n        tex = Tex('Hello 你好 \\\\LaTeX 日本語でおk', tex_template=TexTemplateLibrary.ctex, font_size=144)\n        self.add(tex)"
  },
  {
    "objectID": "posts/2021-07-04-upload_file_to_google_shared_drive.html",
    "href": "posts/2021-07-04-upload_file_to_google_shared_drive.html",
    "title": "golangでサービスアカウント認証の下、google driveの共有ドライブへファイルをアップロードする",
    "section": "",
    "text": "google drive apiを使ってファイルをアップロードする方法は公式の解説ではgolangのドキュメントが貧弱だ. golangからサービスアカウントで認証し, 共有ドライブ(shared drive)へファイルのアップロードを行おうとするとGoogle APIs Client Library for Goを解読する必要がある. quickstartではOAuth 2.0認証を使ってマイドライブ(mydrive)のファイル一覧を表示するサンプルがある. 少し検索するとOAuth 2.0認証やサービスアカウントでマイドライブへファイルをアップロードする方法が見つかるが, 共有ドライブへのアップロード方法は見つけることができなかったのでその方法を紹介する."
  },
  {
    "objectID": "posts/2021-07-04-upload_file_to_google_shared_drive.html#準備",
    "href": "posts/2021-07-04-upload_file_to_google_shared_drive.html#準備",
    "title": "golangでサービスアカウント認証の下、google driveの共有ドライブへファイルをアップロードする",
    "section": "準備",
    "text": "準備\n\nshared driveにdirectoryを作成する(driveIdはhttps://drive.google.com/drive/folders/XXX のXXX部分)\nサービスアカウントを発行しcredential.jsonを保存する\ngoogle driveの画面 &gt; メンバーを管理 でサービスアカウントを追加し投稿者権限を付与する"
  },
  {
    "objectID": "posts/2021-07-04-upload_file_to_google_shared_drive.html#サンプルコード",
    "href": "posts/2021-07-04-upload_file_to_google_shared_drive.html#サンプルコード",
    "title": "golangでサービスアカウント認証の下、google driveの共有ドライブへファイルをアップロードする",
    "section": "サンプルコード",
    "text": "サンプルコード\n以下のコードはsample.txtをshared driveへアップロードする. driveIdを上の説明を参考に書き換えた後sample.txt, credential.jsonを同じディレクトリに置いて実行する. shared driveへファイルをアップロードするにはSupportsAllDrives(true)とする必要があり, ここに辿り着くまでに時間がかかり面倒だった.\n\n\nCode\npackage main\n\nimport (\n\n    \"encoding/json\"\n    \"io/ioutil\"\n    \"log\"\n    \"net/http\"\n    \"os\"\n    \"google.golang.org/api/drive/v3\"\n    \"golang.org/x/oauth2\"\n    \"golang.org/x/oauth2/google\"\n    \"golang.org/x/oauth2/jwt\"\n)\n\n// ServiceAccount : Use Service account\nfunc ServiceAccount(credentialFile string) *http.Client {\n    b, err := ioutil.ReadFile(credentialFile)\n    if err != nil {\n        log.Fatal(err)\n    }\n    var c = struct {\n        Email      string `json:\"client_email\"`\n        PrivateKey string `json:\"private_key\"`\n    }{}\n    json.Unmarshal(b, &c)\n    config := &jwt.Config{\n        Email:      c.Email,\n        PrivateKey: []byte(c.PrivateKey),\n        Scopes: []string{\n            drive.DriveScope,\n        },\n        TokenURL: google.JWTTokenURL,\n    }\n    client := config.Client(oauth2.NoContext)\n    return client\n}\n\n\nfunc main() {\n\n\n    filePath := \"sample.txt\"     // file path \n    driveId := \"XXX\"\n    \n    //use survice account\n    client := ServiceAccount(\"credential.json\") // Please set the json file of Service account.\n    \n    srv, err := drive.New(client)\n    if err != nil {\n        log.Fatalf(\"Unable to retrieve drive Client %v\", err)\n    }\n\n    uploadFile, err := os.Open(filePath)\n    if err != nil {\n        log.Fatalf(\"Cannot find such file %v\", err)\n    }\n\n    folderIdList := [] string{driveId}\n    f := &drive.File{Name: filePath, Parents: folderIdList}\n\n    _, err = srv.Files.Create(f).SupportsAllDrives(true).Media(uploadFile).Do()\n    if err != nil {\n        log.Fatalf(\"Upload Failed %v\", err)\n    }\n\n}"
  },
  {
    "objectID": "posts/2021-07-12-database_memo.html",
    "href": "posts/2021-07-12-database_memo.html",
    "title": "Database memo",
    "section": "",
    "text": "データベース管理システム チュートリアル: tutorial\n\n\nbrew install postgresql\n確認\npostgres\nこれでサーバーが起動する(jupyterと同じ). もし以下のように怒られたら\npostgres does not know where to find the server configuration file.\nYou must specify the --config-file or -D invocation option or set the PGDATA environment variable.\n.zshrcに\nexport PGDATA=/usr/local/var/postgres\nを追加する.\n\n\n\nSELECT * FROM pg_indexes\nreference\nhttps://github.com/Homebrew/legacy-homebrew/issues/21920 https://qiita.com/gooddoog/items/1f986c1a6c0f253bd4e2\n\n\n\npsql mydbname\nでデータベースにアクセスし, 対話型で起動する.\npsql -l\nでデータベースの一覧が確認できる.\n\n\n\npythonならpsycopg2 or sqlalchemy, juliaならLibPQを使う. pythonはsqlalchemyがおすすめ. 具体例はpython, juliaを参照. 以下はやや特殊な場合なので必要なら見る.\n\n\nimport psycopg2\nimport pandas as pd\nimport time\nfrom sshtunnel import SSHTunnelForwarder\n\n\ndef queryAurora(sql):\n    with SSHTunnelForwarder(\n        \"ssh_name\",\n        ssh_pkey=\"~/.ssh/id_rsa\",\n        remote_bind_address=(\"hogehoge\", 5432)\n    ) as server:\n        conn = psycopg2.connect(\n            host='localhost',\n            port=server.local_bind_port,\n            dbname='hogedb',\n            user='foo',\n            password='bar')\n        cur = conn.cursor()\n        cur.execute(sql)\n        result = cur.fetchall()\n        colnames = [col.name for col in cur.description]\n        # pandas.DataFrameで返す用の処理\n        new_result = [[one for one in one_result]  for one_result in result]\n        result = pd.DataFrame(new_result,columns=colnames)\n        cur.close()\n        conn.close()\n        # 連続で叩くと凄くヤバいので1秒待つ\n        time.sleep(1)\n        return resul\n\n\n\nusing LibPQ\n\nfunction sql(query)\n    conn = LibPQ.Connection(\"dbname='hogedb' host='localhost' user='foo' password='bar' port=45432\")\n    result =execute(conn,query)\n    df = DataFrame(result)\n    close(conn)\n    sleep(1)\n    return df\nend\nreference\n\n\n\npgconfig = {\n    'host': 'localhost',\n    'port': 45432,\n    'database': 'hoge',\n    'user': 'foo',\n    'password': 'bar',\n}\n\n%load_ext sql\ndsl = 'postgres://{user}:{password}@{host}:{port}/{database}'.format(**pgconfig)\n%sql $dsl\n\n%%sql\nselect *\nfrom companies c\nwhere name~'Apple'\n変数化したいときは以下のようにやる.\nhogehoge = 'Apple'\n\n%%sql\nselect *\nfrom companies c\nwhere name~hogehoge\n\nreference\nhttps://github.com/catherinedevlin/ipython-sql https://towardsdatascience.com/jupyter-magics-with-sql-921370099589"
  },
  {
    "objectID": "posts/2021-07-12-database_memo.html#install",
    "href": "posts/2021-07-12-database_memo.html#install",
    "title": "Database memo",
    "section": "",
    "text": "brew install postgresql\n確認\npostgres\nこれでサーバーが起動する(jupyterと同じ). もし以下のように怒られたら\npostgres does not know where to find the server configuration file.\nYou must specify the --config-file or -D invocation option or set the PGDATA environment variable.\n.zshrcに\nexport PGDATA=/usr/local/var/postgres\nを追加する."
  },
  {
    "objectID": "posts/2021-07-12-database_memo.html#unique-index",
    "href": "posts/2021-07-12-database_memo.html#unique-index",
    "title": "Database memo",
    "section": "",
    "text": "SELECT * FROM pg_indexes\nreference\nhttps://github.com/Homebrew/legacy-homebrew/issues/21920 https://qiita.com/gooddoog/items/1f986c1a6c0f253bd4e2"
  },
  {
    "objectID": "posts/2021-07-12-database_memo.html#データベースにアクセス",
    "href": "posts/2021-07-12-database_memo.html#データベースにアクセス",
    "title": "Database memo",
    "section": "",
    "text": "psql mydbname\nでデータベースにアクセスし, 対話型で起動する.\npsql -l\nでデータベースの一覧が確認できる."
  },
  {
    "objectID": "posts/2021-07-12-database_memo.html#pythonやjuliaからremoteのpostgressql-queryを叩く方法",
    "href": "posts/2021-07-12-database_memo.html#pythonやjuliaからremoteのpostgressql-queryを叩く方法",
    "title": "Database memo",
    "section": "",
    "text": "pythonならpsycopg2 or sqlalchemy, juliaならLibPQを使う. pythonはsqlalchemyがおすすめ. 具体例はpython, juliaを参照. 以下はやや特殊な場合なので必要なら見る.\n\n\nimport psycopg2\nimport pandas as pd\nimport time\nfrom sshtunnel import SSHTunnelForwarder\n\n\ndef queryAurora(sql):\n    with SSHTunnelForwarder(\n        \"ssh_name\",\n        ssh_pkey=\"~/.ssh/id_rsa\",\n        remote_bind_address=(\"hogehoge\", 5432)\n    ) as server:\n        conn = psycopg2.connect(\n            host='localhost',\n            port=server.local_bind_port,\n            dbname='hogedb',\n            user='foo',\n            password='bar')\n        cur = conn.cursor()\n        cur.execute(sql)\n        result = cur.fetchall()\n        colnames = [col.name for col in cur.description]\n        # pandas.DataFrameで返す用の処理\n        new_result = [[one for one in one_result]  for one_result in result]\n        result = pd.DataFrame(new_result,columns=colnames)\n        cur.close()\n        conn.close()\n        # 連続で叩くと凄くヤバいので1秒待つ\n        time.sleep(1)\n        return resul\n\n\n\nusing LibPQ\n\nfunction sql(query)\n    conn = LibPQ.Connection(\"dbname='hogedb' host='localhost' user='foo' password='bar' port=45432\")\n    result =execute(conn,query)\n    df = DataFrame(result)\n    close(conn)\n    sleep(1)\n    return df\nend\nreference\n\n\n\npgconfig = {\n    'host': 'localhost',\n    'port': 45432,\n    'database': 'hoge',\n    'user': 'foo',\n    'password': 'bar',\n}\n\n%load_ext sql\ndsl = 'postgres://{user}:{password}@{host}:{port}/{database}'.format(**pgconfig)\n%sql $dsl\n\n%%sql\nselect *\nfrom companies c\nwhere name~'Apple'\n変数化したいときは以下のようにやる.\nhogehoge = 'Apple'\n\n%%sql\nselect *\nfrom companies c\nwhere name~hogehoge\n\nreference\nhttps://github.com/catherinedevlin/ipython-sql https://towardsdatascience.com/jupyter-magics-with-sql-921370099589"
  },
  {
    "objectID": "posts/2022-03-10-asdf.html",
    "href": "posts/2022-03-10-asdf.html",
    "title": "asdfのメモ",
    "section": "",
    "text": "これまでpythonのversion管理にpyenvを使ってきた. Macならbrewでpyenvを入れた後使用したいpythonのversionをinstallした.\npyenv install 3.9.7\nproject/directory毎にpythonのversionが違う場合は対象のversionをpyenvでinstallした後\npytnv local 3.8.0\nなどでversionが指定できた. 同様にNode.jsのversion管理はnodenv, javaならjenvなどを使ってきた."
  },
  {
    "objectID": "posts/2022-03-10-asdf.html#pipでinstallしたcli実行可能package",
    "href": "posts/2022-03-10-asdf.html#pipでinstallしたcli実行可能package",
    "title": "asdfのメモ",
    "section": "pipでinstallしたcli実行可能package",
    "text": "pipでinstallしたcli実行可能package\nasdfで適当なpythonを入れてcliで実行可能なpackage, 例えばvirtualenvやjupyterをpipでinstallしたとする. しかしvirtualenvやjupyterは実行できない. 手っ取り早く実行可能にするには次のやり方がある:\nasdf reshim python\nを叩く. ただしこれはinstallする度に毎回実行する必要がある."
  },
  {
    "objectID": "posts/2022-03-10-asdf.html#asdf-direnv",
    "href": "posts/2022-03-10-asdf.html#asdf-direnv",
    "title": "asdfのメモ",
    "section": "asdf-direnv",
    "text": "asdf-direnv\ninstall毎に上記を行うのは面倒なのでasdf-direnvを使う. zshなら\nasdf plugin-add direnv\nasdf direnv setup zsh\nでinstallできる. versionを切り替えたいlocal directoryに.envrcを書く. directoryへ行き\nasdf direnv local python 3.10.4\nでdirenvが設定してくれる. localだけでなく$HOME以下にも.envrcを作ってコマンドを追記するのを忘れずに."
  },
  {
    "objectID": "posts/security_of_cicd.html",
    "href": "posts/security_of_cicd.html",
    "title": "OpenAPIとSchemathesisの紹介",
    "section": "",
    "text": "SchemathesisとはREST APIのtest toolのひとつでopenapi.jsonが与えられた場合それをもとにtest caseを自動生成してリクエストを投げてテストを行ってくれる. 現在のプロジェクトではfastapiを使ってREST APIを開発しているのでopenapi.jsonも自動生成してくれる. APIをクラウドにdeployしたあとリクエストを投げてテストを行いたいがtestコードを書くのが面倒だったのでOpenAPI toolsからいくつか試して一番良かったのがこれである."
  },
  {
    "objectID": "posts/security_of_cicd.html#参考",
    "href": "posts/security_of_cicd.html#参考",
    "title": "OpenAPIとSchemathesisの紹介",
    "section": "参考",
    "text": "参考\n\nOpenAPI wikipedia\nOpenAPI Specification wikipedia"
  },
  {
    "objectID": "posts/security_of_cicd.html#fastapi",
    "href": "posts/security_of_cicd.html#fastapi",
    "title": "OpenAPIとSchemathesisの紹介",
    "section": "fastAPI",
    "text": "fastAPI\nチームで利用しているfastAPIにはopenAPIを利用した機能がいくつかあり, 例えばlocalでAPIを起動するとhttp://127.0.0.1:8000/docs にアクセスすることでswagger UIによってinteractiveなドキュメントを参照することができる.\n\nhttp://127.0.0.1:8000/docs でinteractiveなドキュメントを参照することができる.\nhttp://127.0.0.1:8000/redocs でinteractiveなドキュメントを参照することができる.\nhttp://localhost:8000/openapi.json でopenapi.jsonが得られる.\n\n現在fastAPIが利用しているOSAはversion 3.0.2である. またAPI経由でopenapi.josnが得られるのでこれを利用してAPIのテストを作成したい. ここではCI/CD用にAPIを起動すれば勝手にそのendpointからリクエスト例を取ってきてリクエストを投げるようにしたい. OpenAPI toolsからいくつか試してみた."
  },
  {
    "objectID": "posts/security_of_cicd.html#step-ci",
    "href": "posts/security_of_cicd.html#step-ci",
    "title": "OpenAPIとSchemathesisの紹介",
    "section": "step ci",
    "text": "step ci\nAPIをtestするOSSのtool. OSAからtest用のworkflowを自動生成してtestを実行できる. step ciにはfastapiのintegration機能ある(が別にintegrationしていないと思う):\nstepci generate http://127.0.0.1:8000/openapi.json\nただしこうしてできるworkflow.ymlは文字列がラテン語で生成される箇所がある. これはopenapi.jsonの作りが悪いせいである.\nstepci runの実行:\nstepci run workflow.yml\n\nⓘ  Anonymous usage data collected. Learn more on https://step.ci/privacy\n\n PASS  Default\n\nTests: 0 failed, 1 passed, 1 total\nSteps: 0 failed, 0 skipped, 1 passed, 1 total\nTime:  7.16s, estimated 7s\n\nWorkflow passed after 7.16s\nGive us your feedback on https://step.ci/feedback\ngenerateのオプションでexampleを使う様に指定できるが機能しなかった."
  },
  {
    "objectID": "posts/security_of_cicd.html#schemathesis",
    "href": "posts/security_of_cicd.html#schemathesis",
    "title": "OpenAPIとSchemathesisの紹介",
    "section": "Schemathesis",
    "text": "Schemathesis\n使い方は公式のドキュメントを読んで欲しいが\nschemathesis run http://localhost/openapi.json --hypothesis-phases=explicit -H 'hoge:foo'\nでexampleのリクエストを使ってtestを行ってくれる. また仕事ではalbの関係でheaderも付ける必要があったがそれも問題なかった. dockerのimageも提供されているのでci/cdに組み込んだりdocker-composeでtestを行うのも簡単だった."
  },
  {
    "objectID": "posts/2021-07-12-julia_memo.html",
    "href": "posts/2021-07-12-julia_memo.html",
    "title": "julia memo",
    "section": "",
    "text": "Code\nversioninfo()\n\n\nJulia Version 1.6.1\nCommit 6aaedecc44 (2021-04-23 05:59 UTC)\nPlatform Info:\n  OS: macOS (x86_64-apple-darwin18.7.0)\n  CPU: Intel(R) Core(TM) i7-8557U CPU @ 1.70GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\nEnvironment:\n  JULIA_NUM_THREADS = 8"
  },
  {
    "objectID": "posts/2021-07-12-julia_memo.html#配列のfor文",
    "href": "posts/2021-07-12-julia_memo.html#配列のfor文",
    "title": "julia memo",
    "section": "配列のfor文",
    "text": "配列のfor文\n多次元配列と配列の配列を混同してfor文を間違えることがある. 適当な多次元配列\\(x\\)があるとする.\n\n\nCode\nx = rand(1:5, 10, 3)\n\n\n10×3 Matrix{Int64}:\n 2  1  3\n 1  1  5\n 5  1  1\n 4  1  2\n 3  5  5\n 5  4  3\n 4  4  4\n 5  4  2\n 1  5  5\n 3  5  2\n\n\nfor文で多次元配列を回そうとすると全ての要素を縦になめる:\n\n\nCode\nfor e in x\n    println(e)\nend\n\n\n2\n1\n5\n4\n3\n5\n4\n5\n1\n3\n1\n1\n1\n1\n5\n4\n4\n4\n5\n5\n3\n5\n1\n2\n5\n3\n4\n2\n5\n2\n\n\n行ごとに回したければeachrowを使う:\n\n\nCode\nfor row in eachrow(x)\n    println(row)\nend\n\n\n[2, 1, 3]\n[1, 1, 5]\n[5, 1, 1]\n[4, 1, 2]\n[3, 5, 5]\n[5, 4, 3]\n[4, 4, 4]\n[5, 4, 2]\n[1, 5, 5]\n[3, 5, 2]\n\n\n\n\nCode\nfor col in eachcol(x)\n    println(col)\nend\n\n\n[2, 1, 5, 4, 3, 5, 4, 5, 1, 3]\n[1, 1, 1, 1, 5, 4, 4, 4, 5, 5]\n[3, 5, 1, 2, 5, 3, 4, 2, 5, 2]"
  },
  {
    "objectID": "posts/2021-07-12-julia_memo.html#listをつなげて文字列にして出力する場合はjoinの方が早い",
    "href": "posts/2021-07-12-julia_memo.html#listをつなげて文字列にして出力する場合はjoinの方が早い",
    "title": "julia memo",
    "section": "listをつなげて文字列にして出力する場合はjoinの方が早い",
    "text": "listをつなげて文字列にして出力する場合はjoinの方が早い\nと以前atcoderでハマったのでメモしようと思ったが試してみるとなぜかfor文ベタ書きが一番早い.\n\n\nCode\nl=rand(0:9,100);\n\n\n\n\nCode\n@time println(join(l))\n\n\n9003464350455442362738102226859217991002631105006012661620360406555247703162576929699877728261059317\n  0.001320 seconds (228 allocations: 10.438 KiB)\n\n\n\n\nCode\ns=\"\"\nfor n in l\n    s*=string(n)\nend\n@time println(s)\n\n\n9003464350455442362738102226859217991002631105006012661620360406555247703162576929699877728261059317\n  0.000147 seconds (21 allocations: 640 bytes)\n\n\n\n\nCode\nfunction j(l)\n println(join(l))\nend\n@time j(l)\n\n\n9003464350455442362738102226859217991002631105006012661620360406555247703162576929699877728261059317\n  0.004714 seconds (1.05 k allocations: 59.887 KiB, 93.06% compilation time)\n\n\n\n\nCode\nfunction jj(l)\ns=\"\"\nfor n in l\n    s*=string(n)\nend\nprintln(s)\nend\n@time jj(l)\n\n\n9003464350455442362738102226859217991002631105006012661620360406555247703162576929699877728261059317\n  0.012173 seconds (4.91 k allocations: 249.832 KiB, 96.46% compilation time)\n\n\n\n\n\n\n\nCode\n@time begin\ns=\"\"\nfor n in l\n    s*=string(n)\nend\n println(s)\nend\n\n\n9003464350455442362738102226859217991002631105006012661620360406555247703162576929699877728261059317\n  0.000244 seconds (421 allocations: 20.469 KiB)"
  },
  {
    "objectID": "posts/2021-07-12-mac_memo.html",
    "href": "posts/2021-07-12-mac_memo.html",
    "title": "Mac memo",
    "section": "",
    "text": "Karabiner-Elements: キー配置やキーバインドを変更できる.\nAmphetamine: (Caffeinの代わり) スリープ on/off\nSourcetree: gitのGUIアプリ, backlogとの連携はちょっとめんどくさいのでググる.\nDBeaver: SQLを叩くためののGUI\nQueryPie: SQLを叩くためののGUI開発終了した.\nkeybase\n\n\n\n\n\nBetter Touch Tool トラックパッドやキーボードショートカットをカスタマイズができる.\nStay 外部モニターを使ったあとのアプリ配置がぐちゃぐちゃになる問題を解消してくれる.\nintelliJ IDE: めっちゃ便利らしい. 全然便利じゃない.\n\n\n\n\nマスタースライドでヒラギノフォントが設定できない問題\nhttp://btgr.hateblo.jp/entry/2016/03/22/214044\n\n\n\nosxfuseを使う\n\n\n\n拡張子があれば右クリック&gt;情報から変更できるがない場合はこの方法では変更ができない. githubに素晴らしい方法があった. 例えばemacsで開く設定をしたい場合は以下のコマンドで変更できる:\na=`osascript -e 'id of app \"emacs\"'` && \\\ndefaults write com.apple.LaunchServices/com.apple.launchservices.secure LSHandlers -array-add \\\n'{LSHandlerContentType=public.plain-text;LSHandlerRoleAll=$a;}' \\\n'{LSHandlerContentType=public.unix-executable;LSHandlerRoleAll=$a;}' \\\n'{LSHandlerContentType=public.data;LSHandlerRoleAll=$a;}'\nその後再起動する.\n\n\n\nGPUを使ったDNNの計算はNVIDIAのGPUが主流だがmacではNVIDIAのGPUが使えない. (会社で誰も使わず腐っていた)BlackMagic(外付けgpu)でDNNを使って遊んだのでそのメモ pythonのDNNモジュールのkerasを使う場合普通の解説ではバックエンドでtensorflowが動く. tensorflowではNVIDIAのgpuを使うが上述の通りmacではnvidiaが使えない. そこで代わりにバックエンドとしてPlaidMLを使いkerasが動く環境を構築する.\n\nモニターとgpuをHDMIで, gpuとmacをthunderbolt3で繋げてモニターにデスクトップが表示させるか確認 (普通のgpuの使い方はここを参照 https://support.apple.com/ja-jp/HT208544 )\npythonの仮想環境を設定(しなくてもよいがしておいた方が無難)\npipでkeras, plaidml-keras, おまけでベンチマーク用plaidbenchと必要なmoduleをインストール\npip install keras plaidml-keras plaidbench\nPlaidmlを設定(https://github.com/plaidml/plaidml) ターミナルで\nplaidml-setup\nを叩く. その後experimental dviceを使うかどうか\nUsing experimental devices can cause poor performance, crashes, and\nother nastiness.\n\nEnable experimental device support? (y,n)[n]: =の後どのgpuを使うか=\nMultiple devices detected (You can override by setting\nPLAIDML_DEVICE_IDS). Please choose a default device:\n\n1 : metal_intel(r)_iris(tm)_plus_graphics_645.0 2 :\nmetal_amd_radeon_pro_580.0\n\nDefault device? (1,2)[1]:\nを聞かれるので, 適当に選んで( n –&gt; 2 : metalamdradeonpro580.0とした)設定し、saveを選ぶ.\nターミナルで=\nplaidbench keras mobilenet\nを叩いてベンチマークする.\npythonのコードを書く時kerasをinmportするより前の方に\nimport os\nimport time\nos.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\nを追加すればバックエンドをplaidmlにしてkerasを動かすことができる.\n以下の適当に拾ってきたコードが動けばOK\nimport os\nimport time\nos.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n\nimport numpy as np\nimport keras\nimport keras.applications as kapp\nfrom keras.datasets import cifar10\n\n(x_train, y_train_cats), (x_test, y_test_cats) = cifar10.load_data()\nbatch_size = 8 x_train = x_train[:batch_size] x_train =\nnp.repeat(np.repeat(x_train, 7, axis=1), 7, axis=2) model =\nkapp.VGG19() model.compile(optimizer='sgd',\nloss='categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"Running initial batch (compiling tile program)\") y =\nmodel.predict(x=x_train, batch_size=batch_size)\n\n# Now start the clock and run 10 batches print(\"Timing inference...\")\nstart = time.time() for i in range(10): y = model.predict(x=x_train,\nbatch_size=batch_size) print(\"Ran in {} seconds\".format(time.time() -\n                            start)) \n\n後は好きなだけDNNで遊べば良い."
  },
  {
    "objectID": "posts/2021-07-12-mac_memo.html#無料アプリ",
    "href": "posts/2021-07-12-mac_memo.html#無料アプリ",
    "title": "Mac memo",
    "section": "",
    "text": "Karabiner-Elements: キー配置やキーバインドを変更できる.\nAmphetamine: (Caffeinの代わり) スリープ on/off\nSourcetree: gitのGUIアプリ, backlogとの連携はちょっとめんどくさいのでググる.\nDBeaver: SQLを叩くためののGUI\nQueryPie: SQLを叩くためののGUI開発終了した.\nkeybase"
  },
  {
    "objectID": "posts/2021-07-12-mac_memo.html#有料アプリ",
    "href": "posts/2021-07-12-mac_memo.html#有料アプリ",
    "title": "Mac memo",
    "section": "",
    "text": "Better Touch Tool トラックパッドやキーボードショートカットをカスタマイズができる.\nStay 外部モニターを使ったあとのアプリ配置がぐちゃぐちゃになる問題を解消してくれる.\nintelliJ IDE: めっちゃ便利らしい. 全然便利じゃない."
  },
  {
    "objectID": "posts/2021-07-12-mac_memo.html#powerpoint",
    "href": "posts/2021-07-12-mac_memo.html#powerpoint",
    "title": "Mac memo",
    "section": "",
    "text": "マスタースライドでヒラギノフォントが設定できない問題\nhttp://btgr.hateblo.jp/entry/2016/03/22/214044"
  },
  {
    "objectID": "posts/2021-07-12-mac_memo.html#macでssh先をマウントしてfinder操作したいとき",
    "href": "posts/2021-07-12-mac_memo.html#macでssh先をマウントしてfinder操作したいとき",
    "title": "Mac memo",
    "section": "",
    "text": "osxfuseを使う"
  },
  {
    "objectID": "posts/2021-07-12-mac_memo.html#拡張子の無いファイルをfinderで開く際にdefaultのエディターを変更する方法",
    "href": "posts/2021-07-12-mac_memo.html#拡張子の無いファイルをfinderで開く際にdefaultのエディターを変更する方法",
    "title": "Mac memo",
    "section": "",
    "text": "拡張子があれば右クリック&gt;情報から変更できるがない場合はこの方法では変更ができない. githubに素晴らしい方法があった. 例えばemacsで開く設定をしたい場合は以下のコマンドで変更できる:\na=`osascript -e 'id of app \"emacs\"'` && \\\ndefaults write com.apple.LaunchServices/com.apple.launchservices.secure LSHandlers -array-add \\\n'{LSHandlerContentType=public.plain-text;LSHandlerRoleAll=$a;}' \\\n'{LSHandlerContentType=public.unix-executable;LSHandlerRoleAll=$a;}' \\\n'{LSHandlerContentType=public.data;LSHandlerRoleAll=$a;}'\nその後再起動する."
  },
  {
    "objectID": "posts/2021-07-12-mac_memo.html#macでのgpuの設定",
    "href": "posts/2021-07-12-mac_memo.html#macでのgpuの設定",
    "title": "Mac memo",
    "section": "",
    "text": "GPUを使ったDNNの計算はNVIDIAのGPUが主流だがmacではNVIDIAのGPUが使えない. (会社で誰も使わず腐っていた)BlackMagic(外付けgpu)でDNNを使って遊んだのでそのメモ pythonのDNNモジュールのkerasを使う場合普通の解説ではバックエンドでtensorflowが動く. tensorflowではNVIDIAのgpuを使うが上述の通りmacではnvidiaが使えない. そこで代わりにバックエンドとしてPlaidMLを使いkerasが動く環境を構築する.\n\nモニターとgpuをHDMIで, gpuとmacをthunderbolt3で繋げてモニターにデスクトップが表示させるか確認 (普通のgpuの使い方はここを参照 https://support.apple.com/ja-jp/HT208544 )\npythonの仮想環境を設定(しなくてもよいがしておいた方が無難)\npipでkeras, plaidml-keras, おまけでベンチマーク用plaidbenchと必要なmoduleをインストール\npip install keras plaidml-keras plaidbench\nPlaidmlを設定(https://github.com/plaidml/plaidml) ターミナルで\nplaidml-setup\nを叩く. その後experimental dviceを使うかどうか\nUsing experimental devices can cause poor performance, crashes, and\nother nastiness.\n\nEnable experimental device support? (y,n)[n]: =の後どのgpuを使うか=\nMultiple devices detected (You can override by setting\nPLAIDML_DEVICE_IDS). Please choose a default device:\n\n1 : metal_intel(r)_iris(tm)_plus_graphics_645.0 2 :\nmetal_amd_radeon_pro_580.0\n\nDefault device? (1,2)[1]:\nを聞かれるので, 適当に選んで( n –&gt; 2 : metalamdradeonpro580.0とした)設定し、saveを選ぶ.\nターミナルで=\nplaidbench keras mobilenet\nを叩いてベンチマークする.\npythonのコードを書く時kerasをinmportするより前の方に\nimport os\nimport time\nos.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\nを追加すればバックエンドをplaidmlにしてkerasを動かすことができる.\n以下の適当に拾ってきたコードが動けばOK\nimport os\nimport time\nos.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n\nimport numpy as np\nimport keras\nimport keras.applications as kapp\nfrom keras.datasets import cifar10\n\n(x_train, y_train_cats), (x_test, y_test_cats) = cifar10.load_data()\nbatch_size = 8 x_train = x_train[:batch_size] x_train =\nnp.repeat(np.repeat(x_train, 7, axis=1), 7, axis=2) model =\nkapp.VGG19() model.compile(optimizer='sgd',\nloss='categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"Running initial batch (compiling tile program)\") y =\nmodel.predict(x=x_train, batch_size=batch_size)\n\n# Now start the clock and run 10 batches print(\"Timing inference...\")\nstart = time.time() for i in range(10): y = model.predict(x=x_train,\nbatch_size=batch_size) print(\"Ran in {} seconds\".format(time.time() -\n                            start)) \n\n後は好きなだけDNNで遊べば良い."
  },
  {
    "objectID": "posts/2021-07-12-jupyter_settings.html",
    "href": "posts/2021-07-12-jupyter_settings.html",
    "title": "jupyter settings",
    "section": "",
    "text": "from notebook.services.config import ConfigManager\n\nc = ConfigManager()\nc.update('notebook',\n         {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})\n\n\n\nviewの項目から変更できる.\n\n注意 2019/12/2現在nbextensionとjupyterthemesを同時に使うと行番号の表示がおかしくなる.\n\n\n\n\npip install jupyterthemes\nhttps://github.com/dunovank/jupyter-themes\n現在のお気に入り\njt -t chesterish -f hack -fs 120 -ofs 100 -tfs 11 -nfs 115 -cellw 100% -T -N -kl\n\n注意 テーマを変えると=.jupyter/custom=が上書きされる.\n\n\n\n\nhttps://github.com/jupyter/jupyter/wiki/Jupyter-kernels\n\n\n\nsshでリモート先へ接続しjupyterを起動する. その際ポートフォワードする:\nssh $user@$ip-address -L 8989:localhost:8888\njupyter notebook & \nこれでブラウザからlocalhost:8889とすればjupyterに繋がる. 8890:localhost:8888とするとmac側でブラウザに入力するときにlocalhost:8890となる. nohupでjupyterを立ち上げた場合はポートフォワーディングから再開できる. jupyter labを使いたい場合は\njupyter lab --no-browser\nで起動する.\n\n\n\nnohupを使う. 例えば\nnohup jupyter notebook --no-browser &\nで接続を切って再接続ができる.\n\n追記\n\njupyter notebook &\nでもOK.\nプロセスを終了するには\njupyter notebook list\nでportを調べる.\njupyter notebook stop\nで終了するか\nnetstat -tulpn\nでpidを確認し\nkill $pid\nでプロセスを終了.\nwolfram kernel等はプロセスとして生き残っている可能性がある.\n\n\nhttps://blog.amedama.jp/entry/jupyter-nb-ssh-port-forwardin https://gist.github.com/33eyes/e1da2d78979dc059433849c466ff5996"
  },
  {
    "objectID": "posts/2021-07-12-jupyter_settings.html#括弧補完をオフにする",
    "href": "posts/2021-07-12-jupyter_settings.html#括弧補完をオフにする",
    "title": "jupyter settings",
    "section": "",
    "text": "from notebook.services.config import ConfigManager\n\nc = ConfigManager()\nc.update('notebook',\n         {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})"
  },
  {
    "objectID": "posts/2021-07-12-jupyter_settings.html#行番号をデフォルトで表示する",
    "href": "posts/2021-07-12-jupyter_settings.html#行番号をデフォルトで表示する",
    "title": "jupyter settings",
    "section": "",
    "text": "viewの項目から変更できる.\n\n注意 2019/12/2現在nbextensionとjupyterthemesを同時に使うと行番号の表示がおかしくなる."
  },
  {
    "objectID": "posts/2021-07-12-jupyter_settings.html#見た目を変える",
    "href": "posts/2021-07-12-jupyter_settings.html#見た目を変える",
    "title": "jupyter settings",
    "section": "",
    "text": "pip install jupyterthemes\nhttps://github.com/dunovank/jupyter-themes\n現在のお気に入り\njt -t chesterish -f hack -fs 120 -ofs 100 -tfs 11 -nfs 115 -cellw 100% -T -N -kl\n\n注意 テーマを変えると=.jupyter/custom=が上書きされる."
  },
  {
    "objectID": "posts/2021-07-12-jupyter_settings.html#kernel一覧",
    "href": "posts/2021-07-12-jupyter_settings.html#kernel一覧",
    "title": "jupyter settings",
    "section": "",
    "text": "https://github.com/jupyter/jupyter/wiki/Jupyter-kernels"
  },
  {
    "objectID": "posts/2021-07-12-jupyter_settings.html#shhでのjupyter利用法",
    "href": "posts/2021-07-12-jupyter_settings.html#shhでのjupyter利用法",
    "title": "jupyter settings",
    "section": "",
    "text": "sshでリモート先へ接続しjupyterを起動する. その際ポートフォワードする:\nssh $user@$ip-address -L 8989:localhost:8888\njupyter notebook & \nこれでブラウザからlocalhost:8889とすればjupyterに繋がる. 8890:localhost:8888とするとmac側でブラウザに入力するときにlocalhost:8890となる. nohupでjupyterを立ち上げた場合はポートフォワーディングから再開できる. jupyter labを使いたい場合は\njupyter lab --no-browser\nで起動する."
  },
  {
    "objectID": "posts/2021-07-12-jupyter_settings.html#ssh接続を切っても計算を続けさせる方法",
    "href": "posts/2021-07-12-jupyter_settings.html#ssh接続を切っても計算を続けさせる方法",
    "title": "jupyter settings",
    "section": "",
    "text": "nohupを使う. 例えば\nnohup jupyter notebook --no-browser &\nで接続を切って再接続ができる.\n\n追記\n\njupyter notebook &\nでもOK.\nプロセスを終了するには\njupyter notebook list\nでportを調べる.\njupyter notebook stop\nで終了するか\nnetstat -tulpn\nでpidを確認し\nkill $pid\nでプロセスを終了.\nwolfram kernel等はプロセスとして生き残っている可能性がある.\n\n\nhttps://blog.amedama.jp/entry/jupyter-nb-ssh-port-forwardin https://gist.github.com/33eyes/e1da2d78979dc059433849c466ff5996"
  },
  {
    "objectID": "posts/2021-07-14-examples_to_connect_dbs_in_julia.html",
    "href": "posts/2021-07-14-examples_to_connect_dbs_in_julia.html",
    "title": "Connect databses in Julia",
    "section": "",
    "text": "Code\nversioninfo()\n\n\nJulia Version 1.6.1\nCommit 6aaedecc44 (2021-04-23 05:59 UTC)\nPlatform Info:\n  OS: macOS (x86_64-apple-darwin18.7.0)\n  CPU: Intel(R) Core(TM) i7-8557U CPU @ 1.70GHz\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\nEnvironment:\n  JULIA_NUM_THREADS = 8\n\n\n\n\nCode\nusing GBQ\n\n\n\n\nCode\n# use .env\nusing DotEnv\nDotEnv.config(path = \"/Users/kameyama/.env\")\naurora=\"dbname='$(ENV[\"WRITE_RDB_DATABASE\"])' host='$(ENV[\"WRITE_RDB_HOST\"])' user='$(ENV[\"WRITE_RDB_USERNAME\"])' password='$(ENV[\"WRITE_RDB_PASSWORD\"])' port=$(ENV[\"WRITE_RDB_PORT\"])\"\nredshift=\"dbname='$(ENV[\"DWH_DATABASE\"])' host='$(ENV[\"DWH_HOST\"])' user='$(ENV[\"DWH_USERNAME\"])' password='$(ENV[\"DWH_PASSWORD\"])' port=$(ENV[\"DWH_PORT\"])\"\nproject_name=ENV[\"BQ_PROJECT_NAME\"]\ndataset_name=ENV[\"BQ_DATASET_NAME\"]\n;\n\n\n\n\nCode\nusing LibPQ\nusing DataFrames\n# next two packages conflict with each other at the macro @select\nusing DataFramesMeta\n# using Queryverse #packages for dataframes \n\n\n\n\nCode\nusing Format\n\n\n\n\nCode\nfunction sql(query,conn_str)\n    conn = LibPQ.Connection(conn_str; options=Dict{String, String}())\n    result =execute(conn,query)\n    df = DataFrame(result)\n    close(conn)\n    return df\nend \n\n\nsql (generic function with 1 method)\n\n\n\n\nCode\nfunction sql_time(query1,query2)\n    print(\"Aurora: \")\n    @time sql(query1,aurora)\n    print(\"Redshift: \")\n    @time sql(query1,redshift)\n    print(\"Bigquery: \")\n    @time gbq_query(query2)\nend\n\n\nsql_time (generic function with 1 method)\n\n\n\n\nCode\nquery=\"select * from {}companies\"\nquery1=format(query,\"\")\nquery2=format(query,project_name*\".\"*dataset_name*\".\")\n\n\n\"select * from prod-tameike-219208.smart.companies\"\n\n\n\n\nCode\nsql_time(query1,query2);\n\n\nAurora:   0.485374 seconds (202.23 k allocations: 7.152 MiB)\nRedshift:   0.265902 seconds (211.10 k allocations: 7.288 MiB)\nBigquery:   2.751780 seconds (142.51 k allocations: 14.153 MiB)\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/2022-01-21-great_expextations.html",
    "href": "posts/2022-01-21-great_expextations.html",
    "title": "great expectationsの紹介",
    "section": "",
    "text": "はじめに\ngreatexpectationsはデータのvalidating, documenting, profilingのためのpythonライブラリ. pythonのライブラリなのでpythonのコードに組み込みやすいのでpythonユーザーにおすすめ. 又, shellコマンドも充実しているのでshell scriptで上記の処理を行いたい人にもおすすめ.\ngreat expectationsは大雑把に\n\ndata context (great expectations全体の設定)\ndata source (validation data用のディレクトリ)\nexpectation suite (validationの設定)\ncheckpoint (validationの実行とその結果の保存)\ndata docs (expectation suiteやcheckpointの結果の可視化)\n\nから構成されておりこれらがtutorialで概要が把握できる. なのでまずはをやるとよい.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "notebooks2",
    "section": "",
    "text": "uvicorn vs gunicorn\n\n\n\n\n\n\n\nfastapi\n\n\n\n\nfastapiを使う際のuvicornとgunicornの違い\n\n\n\n\n\n\nDec 22, 2023\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nstepciのworkflow.yamlの上手かもしれない書き方\n\n\n\n\n\n\n\n[dev, ci/cd, memo]\n\n\n\n\nAPIのテストツール\n\n\n\n\n\n\nJun 5, 2023\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nOpenAPIとSchemathesisの紹介\n\n\n\n\n\n\n\ndev, openapi\n\n\n\n\nOpenAPIに従ってrest apiへリクエストを投げるパッケージ\n\n\n\n\n\n\nMay 21, 2023\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nAmazon Sagemakerの感想\n\n\n\n\n\n\n\nGCP, AWS\n\n\n\n\n1週間くらい調査してみた感想\n\n\n\n\n\n\nMay 8, 2023\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\njupyter settings\n\n\n\n\n\n\n\nmemo, jupyter\n\n\n\n\nJupyter settings for myself\n\n\n\n\n\n\nJul 12, 2022\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\ndocker image from scratch\n\n\n\n\n\n\n\ndocker\n\n\n\n\ndocker imageをscratchから作る\n\n\n\n\n\n\nJun 29, 2022\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nasdfのメモ\n\n\n\n\n\n\n\nmemo\n\n\n\n\npyenvからasdfへ移行を例に\n\n\n\n\n\n\nMar 10, 2022\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nmanimのメモ\n\n\n\n\n\n\n\nmemo, manim\n\n\n\n\nmanim\n\n\n\n\n\n\nMar 10, 2022\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\ngreat expectationsの紹介\n\n\n\n\n\n\n\npython\n\n\n\n\nグレートですよこいつはァ\n\n\n\n\n\n\nJan 21, 2022\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nuse org-mode like jupyter\n\n\n\n\n\n\n\njupyter, emacs\n\n\n\n\norg-modeをjupyterのように使う方法\n\n\n\n\n\n\nJan 11, 2022\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\npost org-mode files via fastpages\n\n\n\n\n\n\n\nmemo\n\n\n\n\nA guide of posting org-mode files\n\n\n\n\n\n\nJan 10, 2022\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nConnect databses in Julia\n\n\n\n\n\n\n\njulia\n\n\ndatabase\n\n\naws\n\n\ngcp\n\n\nbigquery\n\n\n\n\nExamples to connect db in Julia\n\n\n\n\n\n\nJul 29, 2021\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\njulia memo\n\n\n\n\n\n\n\njulia\n\n\ndatabase\n\n\naws\n\n\ngcp\n\n\nbigquery\n\n\n\n\n(自分が)よく間違えるjuliaの構文をまとめる\n\n\n\n\n\n\nJul 29, 2021\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nConnect databses in Python\n\n\n\n\n\n\n\npython\n\n\ndatabase\n\n\naws\n\n\ngcp\n\n\nbigquery\n\n\n\n\nExamples to connect db in Python\n\n\n\n\n\n\nJul 29, 2021\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nUbuntu memo\n\n\n\n\n\n\n\nmemo, ubuntu\n\n\n\n\nUbuntu memo for myself\n\n\n\n\n\n\nJul 12, 2021\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nJulia setup & settings\n\n\n\n\n\n\n\njulia\n\n\n\n\nJulia setup & settings for myself\n\n\n\n\n\n\nJul 12, 2021\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nMac memo\n\n\n\n\n\n\n\nmemo, mac\n\n\n\n\nMac memo for myself\n\n\n\n\n\n\nJul 12, 2021\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\nDatabase memo\n\n\n\n\n\n\n\nmemo, database\n\n\n\n\nA DB memo for myself\n\n\n\n\n\n\nJul 12, 2021\n\n\nMasaya Kameyama\n\n\n\n\n\n\n  \n\n\n\n\ngolangでサービスアカウント認証の下、google driveの共有ドライブへファイルをアップロードする\n\n\n\n\n\n\n\ngolang\n\n\n\n\nThe first post\n\n\n\n\n\n\nJul 4, 2021\n\n\nMasaya Kameyama\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html",
    "href": "posts/2021-07-12-ubuntu_memo.html",
    "title": "Ubuntu memo",
    "section": "",
    "text": "インストール用DVDを突っ込んでインストール以下の２点に気をつける\n\nGPUの設定のためInstall Ubuntuにカーソルをあわせてe quiet splash --- を quiet splash nomodeset --- に変更しctrl + x\n自動ログイン https://forums.ubuntulinux.jp/viewtopic.php?id=19823\n\n\n\nUbuntuのインストールをします。その際、インストールウィザードのアカウント設定画面で「自動ログイン」を有効にしておきます。 2. インストール完了後に再起動をすると、ログイン画面がスキップされ、正常にデスクトップ画面が表示されます。 3. 端末を起動し、以下をコピペしたのち実行します。実行時にはアカウントのパスワードを要求されるので、入力します。 sudo gedit /etc/gdm3/custom.conf 4. コマンドの実行によって、テキストエディタ「gedit」で、ファイル「custom.conf」が開かれます。「#WaylandEnable=false」という記述を探し、当該の「#」を削除、gedit画面右上の「保存」ボタンをクリックし、上書き保存をします。 5. 「設定」を起動し、左ペインの項目から「詳細」→「ユーザー 」と辿り、「自動ログイン」を「オフ」にします。 6. PCを再起動し、ログイン画面が正常に表示されれば、作業は完了です。\n\n最初にapt(macOSでのhomebrewみたいな奴)を更新しておく\nsudo apt update\nsudo apt upgrade\nsudo apt-get update\nsudo apt-get upgrade\n\n\n\n重要\n\nhttps://www.tensorflow.org/install/source#common_installation_problems の下の方をみてtensorflow-gpuに対応したCUDAとcuDNNを確認する\n\n\n\n\nnouveau(デフォルトドライバ?)の停止.\n\nsudo lsmod | grep nouveau\nでnouveauの確認.\nsudo emacs /etc/modprobe.d/blacklist-nouveau.conf\nに\nblacklist nouveau\noptions nouveau modeset=0\nを書き込む.\nsudo update-initramfs -u\nsudo ubuntu-drivers autoinstall\nを叩いた後\nsudo reboot\nで再起動.\nnvidia-smi\nで動作確認. 念の為\nsudo lsmod | grep nouveau\n確認し反応なければok.\n\n\n\nくどいがhttps://www.tensorflow.org/install/source#commoninstallationproblems でバージョン確認.\n\nCUDA\nhttps://developer.nvidia.com/cuda-toolkit-archive で必要なCUDAをダウンロードする. バージョンを選択するとインストール方法を教えてくれるのでそれに従う.\nインストール後\nsudo emacs .bashrc\nしてから\nexport PATH=/usr/local/cuda/bin:${PATH}\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:${LD_LIBRARY_PATH}\nでpathを追加.\n再起動して\nnvcc -V\nでバージョン確認\ncuDNN\n公式https://developer.nvidia.com/rdp/cudnn-archive#a-collapse714-9 でバージョンを選択し\n\ncuDNN Library for Linux\ncuDNN Runtime Library for Ubuntu18.04 (Deb)\ncuDNN Developer Library for Ubuntu18.04 (Deb)\ncuDNN Code Samples and User Guide for Ubuntu18.04 (Deb)\n\nをダウンロードする(要登録). ダウンロードディレクトリへ行き下３つは順番に\nsudo dpkg -i $file_name\nとする. 一番上は\ntar xvf $file_name\nsudo cp -a cuda/include/cudnn.h /usr/local/cuda/include/\nsudo cp -a cuda/lib64/libcudnn* /usr/local/cuda/lib64/\nsudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\ncp -r /usr/src/cudnn_samples_v7/ $HOME\ncd $HOME/cudnn_samples_v7/mnistCUDNN\nmake clean && make\nを叩く. pipでtensorflow-gpuとkerasを入れて動作確認(python環境構築を参照).\n\n\n\n\n\nhttps://soinn.esa.io/posts/840\nhttps://qiita.com/k_ikasumipowder/items/5e88ec45f958c35e05ed\nhttps://qiita.com/yukoba/items/4733e8602fa4acabcc35\nhttps://qiita.com/tatsuya11bbs/items/70205b070c7afd7dd651\n\n\n\n\n\nsudo apt install build-essential libbz2-dev libdb-dev \\\nlibreadline-dev libffi-dev libgdbm-dev liblzma-dev \\\nlibncursesw5-dev libsqlite3-dev libssl-dev \\\nzlib1g-dev uuid-dev tk-dev\ni の後\n\npyenvの入れ方(好み) https://qiita.com/micheleno13/items/39ad85cfe44ca32f53ee\n\nあとは好きにpipで色々入れる.\n\n\n\n結局macのようなctrlキーとsuperキーの設定ができなかったのでubuntuをメインに使うことは諦めた. sshで繋げばよい\n\n左commandで検索画面が出る場合の対処法 https://forums.ubuntulinux.jp/viewtopic.php?id=19987\n\n\ngsettings set org.gnome.mutter overlay-key ''\ngsettings set org.gnome.desktop.wm.keybindings switch-input-source \"['Super_L']\"\n\nmacのcommandキーやwinのwindowsキーはlinuxではsuperキー\nusキーボードで日本語を使うための設定 1(fcitixとtweakで管理する) https://www.shujima.work/entry/2018/08/16/174352 https://qiita.com/tokida/items/a89b981680a1ce4523fa\n困ったらfcitixとtweakの設定を見直す\nctrlキーとsuperキーの入れ替え https://qiita.com/teppeitherock/items/113be4c5270f1d5e2f4c\n\n\n\n\n\nhttps://hermemo.com/218/ ここを見てやる\n\n\n\n\nchrome, slack, emacs等を入れる.\n\n\n\n公式をみて入れる. activation回数に限りがあるので注意. (linuxを再インストールして上限に達してしまったがwolframにお願いしたら再アクティベートさせてくれた.)\n\n\n\ngoogle-drive-ocamlfuseを使う (デフォルトで入っっているシステム設定からgoogleを登録するとgoogledriveのディレクトリができるが機能しない)\n\n\n\nOSが入っているssdとは別にhddが付いているが書き込みをする際にはマウントが必要. ホームディレクトリに適当な名前のディレクトリ(例えば=mountvol=)を作り\nsudo mount $マウントしたいhhdのパス $マウント先のディレクトリ\nとする. 自分の場合\nsudo mount /dev/sdb2 mount_vol\nとやる.\n\n\nhttps://mogi2fruits.net/blog/os-software/linux/ubuntu/4263/\nssh\n\nターミナルで\nssh $user_id@$ip_adress\nリモートPC/サーバーへ接続. 下に書いてあるssh/configの設定をしておけば\nssh $host_name\nで繋がる.\n\n\n\n\n自分の場合\nssh kameyama@ip_adress\n設定しておけば\nssh gpu1\n\n\ngit clone等でdockerを用意\n\n4.1.1. 旧バージョン\nターミナルで\nsudo docker-compose build\nで環境構築.\n新バージョン\nターミナルで\nsh build.sh\nで環境構築.\nJupyter\nsudo docker-compose up\nでdocker環境のjuputer notebook起動,\nその後ブラウザからアドレスに\n&lt;ip adress&gt;:&lt;port number&gt;\nでアクセス.\n例えば\n192.xxx.xx.xxx:8899\nなど. port番号は\nsudo emacs docker-compose.yml\nで確認/変更もできる. トークンは入力=dockerfile=内の=Notebook.App.token==を見る.\n\n\n\n\n\n\n\nhttps://qiita.com/mukoya/items/f20def019e25dc162ca8\nssh先をmac finder上にマウント\nbrewでsshfsとosxfuseを入れる.\nsshfs $ユーザー名@$サーバー名:$ディレクトリ $マウントディレクトリ -p $port番号\n例えば\nsshfs kameyama@192.xxx.xx.xxx:/home/kameyama ubuntu -p 22\n\n\n\nhttps://techracho.bpsinc.jp/hachi8833/2019_02_05/66454\n\n\n\n\nサーバー側に公開鍵を渡しておいて、macの=.ssh/config=に\nHost *\n  ForwardAgent yes\n  ServerAliveInterval 60\n  GSSAPIAuthentication no\n  UseKeychain yes\n  AddKeysToAgent yes\n\n\nHost ubuntu\n    HostName &lt;ip address&gt;\n    Port 22\n    User kameyama\n    IdentityFile  ~/.ssh/id_rsa\n    ServerAliveInterval 60\n    AddKeysToAgent yes\n    UseKeychain yes\n\nHost gpu1\n    HostName hogehoge\n    Port 22\n    User kameyama\n    IdentityFile  ~/.ssh/id_rsa\n    ServerAliveInterval 60\n    AddKeysToAgent yes\n    UseKeychain yes\nと書いておけば\nssh ubuntu\nで手元のubuntu計算機に繋がる. 一番上設定はconfigを変更した時にいちいち=ssh-add=をしなくてもよくするためのもの.\n\n\nhttps://qiita.com/0084ken/items/2e4e9ae44ec5e01328f1\n\n\n\n\n\n\nログインシェルから一回読み込まれるのがzprofileとbashprofile. 場合により何度も読まれるのがzshrcやbashrc.\nZshの環境変数は.commonrcに書き込む(commonrcはbashとzshで共通). =zsh -c env=だとzprofileは読まれない. =zsh -l -c env=だとzprofileが読まれる.\n以降はdottofiesはgithubのreadmeのコマンドを叩くだけで良い(変更したらpushする).\nbrewは\nbrew bundle dump --global --force\nで書き出されるのでdotfilesにぶち込む.\nsshなどの設定は公開しない.\n\n\n\nprezto: フレームワーク、見た目が変わったりする peco:履歴参照 ghq: gitを便利にするやつ+\n\npeco\nsshでubuntuのterminalを操作する際pecoがおかしい挙動をする. カーソルキーが使えないのでctrl + n とctrl + pで操作する. +https://www.yuuan.net/item/1017+\n\n\n\n\nubuntuではterminal起動時に=.bashrc=が読み込まれるがsshで繋いだ場合=.bashprofile=が読み込まれる. そこで.=bashprofile=に\n# .bashrc\nif [ -f ~/.bashrc ]; then\n        . ~/.bashrc\nfi\nと書いてsshでも=.bashrc=を読み込むようにする."
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#インストール間違えると起動がおかしくなる",
    "href": "posts/2021-07-12-ubuntu_memo.html#インストール間違えると起動がおかしくなる",
    "title": "Ubuntu memo",
    "section": "",
    "text": "インストール用DVDを突っ込んでインストール以下の２点に気をつける\n\nGPUの設定のためInstall Ubuntuにカーソルをあわせてe quiet splash --- を quiet splash nomodeset --- に変更しctrl + x\n自動ログイン https://forums.ubuntulinux.jp/viewtopic.php?id=19823\n\n\n\nUbuntuのインストールをします。その際、インストールウィザードのアカウント設定画面で「自動ログイン」を有効にしておきます。 2. インストール完了後に再起動をすると、ログイン画面がスキップされ、正常にデスクトップ画面が表示されます。 3. 端末を起動し、以下をコピペしたのち実行します。実行時にはアカウントのパスワードを要求されるので、入力します。 sudo gedit /etc/gdm3/custom.conf 4. コマンドの実行によって、テキストエディタ「gedit」で、ファイル「custom.conf」が開かれます。「#WaylandEnable=false」という記述を探し、当該の「#」を削除、gedit画面右上の「保存」ボタンをクリックし、上書き保存をします。 5. 「設定」を起動し、左ペインの項目から「詳細」→「ユーザー 」と辿り、「自動ログイン」を「オフ」にします。 6. PCを再起動し、ログイン画面が正常に表示されれば、作業は完了です。\n\n最初にapt(macOSでのhomebrewみたいな奴)を更新しておく\nsudo apt update\nsudo apt upgrade\nsudo apt-get update\nsudo apt-get upgrade"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#gpu-の設定nvidia-diriver-cuda-cudnn",
    "href": "posts/2021-07-12-ubuntu_memo.html#gpu-の設定nvidia-diriver-cuda-cudnn",
    "title": "Ubuntu memo",
    "section": "",
    "text": "重要\n\nhttps://www.tensorflow.org/install/source#common_installation_problems の下の方をみてtensorflow-gpuに対応したCUDAとcuDNNを確認する\n\n\n\n\nnouveau(デフォルトドライバ?)の停止.\n\nsudo lsmod | grep nouveau\nでnouveauの確認.\nsudo emacs /etc/modprobe.d/blacklist-nouveau.conf\nに\nblacklist nouveau\noptions nouveau modeset=0\nを書き込む.\nsudo update-initramfs -u\nsudo ubuntu-drivers autoinstall\nを叩いた後\nsudo reboot\nで再起動.\nnvidia-smi\nで動作確認. 念の為\nsudo lsmod | grep nouveau\n確認し反応なければok.\n\n\n\nくどいがhttps://www.tensorflow.org/install/source#commoninstallationproblems でバージョン確認.\n\nCUDA\nhttps://developer.nvidia.com/cuda-toolkit-archive で必要なCUDAをダウンロードする. バージョンを選択するとインストール方法を教えてくれるのでそれに従う.\nインストール後\nsudo emacs .bashrc\nしてから\nexport PATH=/usr/local/cuda/bin:${PATH}\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:${LD_LIBRARY_PATH}\nでpathを追加.\n再起動して\nnvcc -V\nでバージョン確認\ncuDNN\n公式https://developer.nvidia.com/rdp/cudnn-archive#a-collapse714-9 でバージョンを選択し\n\ncuDNN Library for Linux\ncuDNN Runtime Library for Ubuntu18.04 (Deb)\ncuDNN Developer Library for Ubuntu18.04 (Deb)\ncuDNN Code Samples and User Guide for Ubuntu18.04 (Deb)\n\nをダウンロードする(要登録). ダウンロードディレクトリへ行き下３つは順番に\nsudo dpkg -i $file_name\nとする. 一番上は\ntar xvf $file_name\nsudo cp -a cuda/include/cudnn.h /usr/local/cuda/include/\nsudo cp -a cuda/lib64/libcudnn* /usr/local/cuda/lib64/\nsudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\ncp -r /usr/src/cudnn_samples_v7/ $HOME\ncd $HOME/cudnn_samples_v7/mnistCUDNN\nmake clean && make\nを叩く. pipでtensorflow-gpuとkerasを入れて動作確認(python環境構築を参照).\n\n\n\n\n\nhttps://soinn.esa.io/posts/840\nhttps://qiita.com/k_ikasumipowder/items/5e88ec45f958c35e05ed\nhttps://qiita.com/yukoba/items/4733e8602fa4acabcc35\nhttps://qiita.com/tatsuya11bbs/items/70205b070c7afd7dd651"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#python環境構築",
    "href": "posts/2021-07-12-ubuntu_memo.html#python環境構築",
    "title": "Ubuntu memo",
    "section": "",
    "text": "sudo apt install build-essential libbz2-dev libdb-dev \\\nlibreadline-dev libffi-dev libgdbm-dev liblzma-dev \\\nlibncursesw5-dev libsqlite3-dev libssl-dev \\\nzlib1g-dev uuid-dev tk-dev\ni の後\n\npyenvの入れ方(好み) https://qiita.com/micheleno13/items/39ad85cfe44ca32f53ee\n\nあとは好きにpipで色々入れる."
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#usキーボード設定",
    "href": "posts/2021-07-12-ubuntu_memo.html#usキーボード設定",
    "title": "Ubuntu memo",
    "section": "",
    "text": "結局macのようなctrlキーとsuperキーの設定ができなかったのでubuntuをメインに使うことは諦めた. sshで繋げばよい\n\n左commandで検索画面が出る場合の対処法 https://forums.ubuntulinux.jp/viewtopic.php?id=19987\n\n\ngsettings set org.gnome.mutter overlay-key ''\ngsettings set org.gnome.desktop.wm.keybindings switch-input-source \"['Super_L']\"\n\nmacのcommandキーやwinのwindowsキーはlinuxではsuperキー\nusキーボードで日本語を使うための設定 1(fcitixとtweakで管理する) https://www.shujima.work/entry/2018/08/16/174352 https://qiita.com/tokida/items/a89b981680a1ce4523fa\n困ったらfcitixとtweakの設定を見直す\nctrlキーとsuperキーの入れ替え https://qiita.com/teppeitherock/items/113be4c5270f1d5e2f4c"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#macbuntumac風レイアウト-sshで繋げば良いのでいらない",
    "href": "posts/2021-07-12-ubuntu_memo.html#macbuntumac風レイアウト-sshで繋げば良いのでいらない",
    "title": "Ubuntu memo",
    "section": "",
    "text": "https://hermemo.com/218/ ここを見てやる"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#アプリケーション",
    "href": "posts/2021-07-12-ubuntu_memo.html#アプリケーション",
    "title": "Ubuntu memo",
    "section": "",
    "text": "chrome, slack, emacs等を入れる."
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#wolfram-engine",
    "href": "posts/2021-07-12-ubuntu_memo.html#wolfram-engine",
    "title": "Ubuntu memo",
    "section": "",
    "text": "公式をみて入れる. activation回数に限りがあるので注意. (linuxを再インストールして上限に達してしまったがwolframにお願いしたら再アクティベートさせてくれた.)"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#google-drive",
    "href": "posts/2021-07-12-ubuntu_memo.html#google-drive",
    "title": "Ubuntu memo",
    "section": "",
    "text": "google-drive-ocamlfuseを使う (デフォルトで入っっているシステム設定からgoogleを登録するとgoogledriveのディレクトリができるが機能しない)"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#ハードディスクマウント",
    "href": "posts/2021-07-12-ubuntu_memo.html#ハードディスクマウント",
    "title": "Ubuntu memo",
    "section": "",
    "text": "OSが入っているssdとは別にhddが付いているが書き込みをする際にはマウントが必要. ホームディレクトリに適当な名前のディレクトリ(例えば=mountvol=)を作り\nsudo mount $マウントしたいhhdのパス $マウント先のディレクトリ\nとする. 自分の場合\nsudo mount /dev/sdb2 mount_vol\nとやる.\n\n\nhttps://mogi2fruits.net/blog/os-software/linux/ubuntu/4263/\nssh\n\nターミナルで\nssh $user_id@$ip_adress\nリモートPC/サーバーへ接続. 下に書いてあるssh/configの設定をしておけば\nssh $host_name\nで繋がる."
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#gpuサーバー使い方",
    "href": "posts/2021-07-12-ubuntu_memo.html#gpuサーバー使い方",
    "title": "Ubuntu memo",
    "section": "",
    "text": "自分の場合\nssh kameyama@ip_adress\n設定しておけば\nssh gpu1\n\n\ngit clone等でdockerを用意\n\n4.1.1. 旧バージョン\nターミナルで\nsudo docker-compose build\nで環境構築.\n新バージョン\nターミナルで\nsh build.sh\nで環境構築.\nJupyter\nsudo docker-compose up\nでdocker環境のjuputer notebook起動,\nその後ブラウザからアドレスに\n&lt;ip adress&gt;:&lt;port number&gt;\nでアクセス.\n例えば\n192.xxx.xx.xxx:8899\nなど. port番号は\nsudo emacs docker-compose.yml\nで確認/変更もできる. トークンは入力=dockerfile=内の=Notebook.App.token==を見る."
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#公開鍵の登録",
    "href": "posts/2021-07-12-ubuntu_memo.html#公開鍵の登録",
    "title": "Ubuntu memo",
    "section": "",
    "text": "https://qiita.com/mukoya/items/f20def019e25dc162ca8\nssh先をmac finder上にマウント\nbrewでsshfsとosxfuseを入れる.\nsshfs $ユーザー名@$サーバー名:$ディレクトリ $マウントディレクトリ -p $port番号\n例えば\nsshfs kameyama@192.xxx.xx.xxx:/home/kameyama ubuntu -p 22\n\n\n\nhttps://techracho.bpsinc.jp/hachi8833/2019_02_05/66454"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#sshconfig設定mac側",
    "href": "posts/2021-07-12-ubuntu_memo.html#sshconfig設定mac側",
    "title": "Ubuntu memo",
    "section": "",
    "text": "サーバー側に公開鍵を渡しておいて、macの=.ssh/config=に\nHost *\n  ForwardAgent yes\n  ServerAliveInterval 60\n  GSSAPIAuthentication no\n  UseKeychain yes\n  AddKeysToAgent yes\n\n\nHost ubuntu\n    HostName &lt;ip address&gt;\n    Port 22\n    User kameyama\n    IdentityFile  ~/.ssh/id_rsa\n    ServerAliveInterval 60\n    AddKeysToAgent yes\n    UseKeychain yes\n\nHost gpu1\n    HostName hogehoge\n    Port 22\n    User kameyama\n    IdentityFile  ~/.ssh/id_rsa\n    ServerAliveInterval 60\n    AddKeysToAgent yes\n    UseKeychain yes\nと書いておけば\nssh ubuntu\nで手元のubuntu計算機に繋がる. 一番上設定はconfigを変更した時にいちいち=ssh-add=をしなくてもよくするためのもの.\n\n\nhttps://qiita.com/0084ken/items/2e4e9ae44ec5e01328f1"
  },
  {
    "objectID": "posts/2021-07-12-ubuntu_memo.html#shellterminal関連",
    "href": "posts/2021-07-12-ubuntu_memo.html#shellterminal関連",
    "title": "Ubuntu memo",
    "section": "",
    "text": "ログインシェルから一回読み込まれるのがzprofileとbashprofile. 場合により何度も読まれるのがzshrcやbashrc.\nZshの環境変数は.commonrcに書き込む(commonrcはbashとzshで共通). =zsh -c env=だとzprofileは読まれない. =zsh -l -c env=だとzprofileが読まれる.\n以降はdottofiesはgithubのreadmeのコマンドを叩くだけで良い(変更したらpushする).\nbrewは\nbrew bundle dump --global --force\nで書き出されるのでdotfilesにぶち込む.\nsshなどの設定は公開しない.\n\n\n\nprezto: フレームワーク、見た目が変わったりする peco:履歴参照 ghq: gitを便利にするやつ+\n\npeco\nsshでubuntuのterminalを操作する際pecoがおかしい挙動をする. カーソルキーが使えないのでctrl + n とctrl + pで操作する. +https://www.yuuan.net/item/1017+\n\n\n\n\nubuntuではterminal起動時に=.bashrc=が読み込まれるがsshで繋いだ場合=.bashprofile=が読み込まれる. そこで.=bashprofile=に\n# .bashrc\nif [ -f ~/.bashrc ]; then\n        . ~/.bashrc\nfi\nと書いてsshでも=.bashrc=を読み込むようにする."
  },
  {
    "objectID": "posts/2021-07-12-julia_setup_and_settings.html",
    "href": "posts/2021-07-12-julia_setup_and_settings.html",
    "title": "Julia setup & settings",
    "section": "",
    "text": "公式からdmgをダウンロードする.\nbrewで入れる or version管理がしたかったらasdfで入れる\n\n\n\n\nコマンドラインで使えるようにするにはエイリアスを作成するかpathを通す. (何故かv1.3のpathが通っているがzshrcには書いていない… エイリアスでもシンボリックリンクでもないのでどういう設定にしたのか?)\n\n\n\nusing Pkg\nPkg.add(\"IJulia\")\n何故かversion1.4では以下が必要だった.\nPkg.build(\"IJulia\")\n\n\n\npackageをgithubから直接installしたい場合がある. 例えばMambaはPkgからインストールするとコケたので最新版をgithubからinstallしたい. githubからinstallする場合は\n# verんsたl 1.0\nPkg.clone(\"https://github.com/JuliaData/DataFramesMeta.jl\") \n# ver 1.4\nPkg.add(PackageSpec(url=\"https://github.com/JuliaDatabases/DBInterface.jl\"))\nなどとする. 念のためパッケージはテストする.\nPkg.test(\"Queryverse\")\n削除は\nPkg.rm(hoge)\nPkg.resolve()\n\n\n~/Library/Jupyter/kernels/julia-1.2/kernel.jsonのenvを編集する.\nref https://ki-chi.jp/?p=992"
  },
  {
    "objectID": "posts/2021-07-12-julia_setup_and_settings.html#インストール",
    "href": "posts/2021-07-12-julia_setup_and_settings.html#インストール",
    "title": "Julia setup & settings",
    "section": "",
    "text": "公式からdmgをダウンロードする.\nbrewで入れる or version管理がしたかったらasdfで入れる"
  },
  {
    "objectID": "posts/2021-07-12-julia_setup_and_settings.html#コマンドライン",
    "href": "posts/2021-07-12-julia_setup_and_settings.html#コマンドライン",
    "title": "Julia setup & settings",
    "section": "",
    "text": "コマンドラインで使えるようにするにはエイリアスを作成するかpathを通す. (何故かv1.3のpathが通っているがzshrcには書いていない… エイリアスでもシンボリックリンクでもないのでどういう設定にしたのか?)"
  },
  {
    "objectID": "posts/2021-07-12-julia_setup_and_settings.html#jupyter-jupyterで使うためにはjulia起動後",
    "href": "posts/2021-07-12-julia_setup_and_settings.html#jupyter-jupyterで使うためにはjulia起動後",
    "title": "Julia setup & settings",
    "section": "",
    "text": "using Pkg\nPkg.add(\"IJulia\")\n何故かversion1.4では以下が必要だった.\nPkg.build(\"IJulia\")"
  },
  {
    "objectID": "posts/2021-07-12-julia_setup_and_settings.html#package",
    "href": "posts/2021-07-12-julia_setup_and_settings.html#package",
    "title": "Julia setup & settings",
    "section": "",
    "text": "packageをgithubから直接installしたい場合がある. 例えばMambaはPkgからインストールするとコケたので最新版をgithubからinstallしたい. githubからinstallする場合は\n# verんsたl 1.0\nPkg.clone(\"https://github.com/JuliaData/DataFramesMeta.jl\") \n# ver 1.4\nPkg.add(PackageSpec(url=\"https://github.com/JuliaDatabases/DBInterface.jl\"))\nなどとする. 念のためパッケージはテストする.\nPkg.test(\"Queryverse\")\n削除は\nPkg.rm(hoge)\nPkg.resolve()\n\n\n~/Library/Jupyter/kernels/julia-1.2/kernel.jsonのenvを編集する.\nref https://ki-chi.jp/?p=992"
  },
  {
    "objectID": "posts/2022-05-29-docker_from_scratch.html",
    "href": "posts/2022-05-29-docker_from_scratch.html",
    "title": "docker image from scratch",
    "section": "",
    "text": "世ははまさに大docker時代、我々はdockerを使った上でプログラムの開発を行っている. プログラムを開発では最終的にdocker imageを作成してdeployする. この際docker imageは公開されている便利なimageを利用して新たなimageを作る. 例えばpythonでhello worldをする実行するdocker imageを作成して実行する一例は次の通りだ:\n\nDockerfile\n\n\nFROM python:3\nCOPY hello.py /\nCMD [\"python\", \"hello.py\"]\n\nhello.py\n\nprint(\"hello\")\ndocker build -t python-hello .\ndocker container run python-hello\nhello\nubuntu 18のimageが欲しければ\ndocker image pull ubuntu:18.04\nでimageを取得できる. このように好きなimageを元に好きなimageを作ることができる.\n所でpythonやubuntu:18.04などのimageはどうやって作られているんだろうか. 我々のような末端ユーザーは公開されているimageを利用するがdocker fileを0から作るにはどうしたら良いのだろうか? そんな時に利用するのがscratch imageだ. この記事ではscratchにhello worldバイナリプログラムを実行するimageをscratchから作成し実行する.\n\n\nドキュメント: ベース・イメージの作成"
  },
  {
    "objectID": "posts/2022-05-29-docker_from_scratch.html#参考",
    "href": "posts/2022-05-29-docker_from_scratch.html#参考",
    "title": "docker image from scratch",
    "section": "",
    "text": "ドキュメント: ベース・イメージの作成"
  },
  {
    "objectID": "posts/2022-01-11-org-jupyter.html",
    "href": "posts/2022-01-11-org-jupyter.html",
    "title": "use org-mode like jupyter",
    "section": "",
    "text": "emacsからjupyterを使用する方法はいくつかありeinが有名である. ここではorg-modeをnotebookのように使う方法を紹介する. emacs-jupyterはorg-modeのcode blockをjupyterで評価可能にする.\n\n\ns=1+1\nprint('Hello world!')\nファイルの先頭に\n\n\n\nと書いておけば以下のように書ける:\ns=1+1\nprint('Hello world!')\nただし標準入力(今の場合標準入力とは言わないかも)は使えない:\nname = input('Name: ')\nprint(f'Hello, {name}!')\nplotも使えない:\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.plot([1, 2, 3, 4], [1, 4, 2, 3])\n\n\n\npythonと同様に先頭に\n\n\n\nを書いておく. pythonと違って入力ができるようになる.\nname = input('Name: ')\nprint(f'Hello, {name}!')\n画像も見れるようになる. (M-x org-toggle-inline-images(C-c C-x C-v)でインライン表示できる.)\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.plot([1, 2, 3, 4], [1, 4, 2, 3])\n\n\n\norg-modeiでjuliaを使うパッケージにはob-juliaがある. ob-juliaは長年メンテナンスされていないので代わりにemacs-jupyterを使う方が良いだろう. emacs-jupyterはメンテナンスされている:\nusing Plots\nprintln(\"hello\")\nplot(sin)"
  },
  {
    "objectID": "posts/2022-01-11-org-jupyter.html#org-modeのcode-blockでpythonを使う一般的なやり方",
    "href": "posts/2022-01-11-org-jupyter.html#org-modeのcode-blockでpythonを使う一般的なやり方",
    "title": "use org-mode like jupyter",
    "section": "",
    "text": "s=1+1\nprint('Hello world!')\nファイルの先頭に\n\n\n\nと書いておけば以下のように書ける:\ns=1+1\nprint('Hello world!')\nただし標準入力(今の場合標準入力とは言わないかも)は使えない:\nname = input('Name: ')\nprint(f'Hello, {name}!')\nplotも使えない:\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.plot([1, 2, 3, 4], [1, 4, 2, 3])"
  },
  {
    "objectID": "posts/2022-01-11-org-jupyter.html#jupyter経由でpythonを使う",
    "href": "posts/2022-01-11-org-jupyter.html#jupyter経由でpythonを使う",
    "title": "use org-mode like jupyter",
    "section": "",
    "text": "pythonと同様に先頭に\n\n\n\nを書いておく. pythonと違って入力ができるようになる.\nname = input('Name: ')\nprint(f'Hello, {name}!')\n画像も見れるようになる. (M-x org-toggle-inline-images(C-c C-x C-v)でインライン表示できる.)\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.plot([1, 2, 3, 4], [1, 4, 2, 3])"
  },
  {
    "objectID": "posts/2022-01-11-org-jupyter.html#juliaを使う",
    "href": "posts/2022-01-11-org-jupyter.html#juliaを使う",
    "title": "use org-mode like jupyter",
    "section": "",
    "text": "org-modeiでjuliaを使うパッケージにはob-juliaがある. ob-juliaは長年メンテナンスされていないので代わりにemacs-jupyterを使う方が良いだろう. emacs-jupyterはメンテナンスされている:\nusing Plots\nprintln(\"hello\")\nplot(sin)"
  },
  {
    "objectID": "posts/2022-01-10-post_org_files_via_fastpages.html",
    "href": "posts/2022-01-10-post_org_files_via_fastpages.html",
    "title": "post org-mode files via fastpages",
    "section": "",
    "text": "Overview(fastpages is already deprecated)\nFastpages is a nice tool to create your homepage written by jupyter notebooks via github pages. You can also make pages by using maekdown and word. However, it can not handle org-mode file. There is a method to use org-mode via fastpages in a blog, but it does not work for me. We soleve it in easy way.\n\n\nCustomize fastpages\nFastpages uses jekyll. Threfore, we use jekyll-org. The customization is easy: modify config.yml and gemfile.\nAdd a next line to config.yml:\nplugins:\n  - jekyll-org\nAdd a next line to Gemfile:\ngem 'jekyll-org', '&gt;= 1.0.2'\n\n\nTemplete\nWe can configure front matter like bellow:\n#+toc: true\n#+layout: post\n#+comments: true\n#+categories: org-mode english\n#+TITLE: post org-mode files via fastpages\n#+description: A guide of posting org-mode files \n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/2021-07-29-examples_to_connect_dbs_in_python.html",
    "href": "posts/2021-07-29-examples_to_connect_dbs_in_python.html",
    "title": "Connect databses in Python",
    "section": "",
    "text": "toc: false\nbranch: master\nbadges: true\ncomments: true\ncategories:\nhide: false\nsearch_exclude: true"
  },
  {
    "objectID": "posts/2021-07-29-examples_to_connect_dbs_in_python.html#sqlalchemy",
    "href": "posts/2021-07-29-examples_to_connect_dbs_in_python.html#sqlalchemy",
    "title": "Connect databses in Python",
    "section": "sqlalchemy",
    "text": "sqlalchemy\n\n\nCode\nimport os\nimport sys\nimport sqlalchemy\nfrom os.path import join, dirname\nfrom dotenv import load_dotenv\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy import Column, Integer, String, create_engine\nfrom sqlalchemy.orm import sessionmaker\nimport pandas as pd\nimport time\ndotenv_path = join(dirname(\"$home\"), '.env')\nload_dotenv(dotenv_path)\nconn_aurora = '{}://{}:{}@{}:{}/{}'.format('postgresql', os.environ['WRITE_RDB_USERNAME'], os.environ['WRITE_RDB_PASSWORD'], os.environ['WRITE_RDB_HOST'], os.environ['WRITE_RDB_PORT'], os.environ['WRITE_RDB_DATABASE'])\nconn_redshift = '{}://{}:{}@{}:{}/{}'.format('postgresql', os.environ['DWH_USERNAME'], os.environ['DWH_PASSWORD'], os.environ['DWH_HOST'], os.environ['DWH_PORT'], os.environ['DWH_DATABASE'])\nengine = create_engine(conn_redshift, echo=True)\n\n\n\n\n\nCode\ndef sql(query):\n    session = sessionmaker(bind=engine)()\n    df = pd.read_sql_query(sql=query, con=engine)\n    time.sleep(1)\n    session.close()\n    return df"
  },
  {
    "objectID": "posts/2021-07-29-examples_to_connect_dbs_in_python.html#psycopg2",
    "href": "posts/2021-07-29-examples_to_connect_dbs_in_python.html#psycopg2",
    "title": "Connect databses in Python",
    "section": "psycopg2",
    "text": "psycopg2\n\n\nCode\nimport psycopg2\nimport pandas as pd\nimport time\nfrom sshtunnel import SSHTunnelForwarder\n\n\ndef queryRedshift(sql):\n    conn = psycopg2.connect(\n        host=os.environ['DWH_HOST'],\n        port=os.environ['DWH_PORT'],\n        dbname=os.environ['DWH_DATABASE'],\n        user=os.environ['DWH_USERNAME'],\n        password=os.environ['DWH_PASSWORD'])\n    cur = conn.cursor()\n    cur.execute(sql)\n    result = cur.fetchall()\n    colnames = [col.name for col in cur.description]\n    # pandas.DataFrameで返す用の処理\n    new_result = [[one for one in one_result]  for one_result in result]\n    result = pd.DataFrame(new_result,columns=colnames)\n    cur.close()\n    conn.close()\n    # 連続で叩くと凄くヤバいので1秒待つ\n    time.sleep(1)\n    return result\n\n\n\n\nCode\nqueryRedshift(q)\n\n\n\n\n\n\n\n\n\nid\n\n\n\n\n0\n1\n\n\n1\n2\n\n\n2\n3\n\n\n3\n4\n\n\n4\n5\n\n\n5\n6\n\n\n6\n7\n\n\n7\n8\n\n\n8\n9\n\n\n9\n10"
  },
  {
    "objectID": "posts/2021-07-29-examples_to_connect_dbs_in_python.html#long-time-query",
    "href": "posts/2021-07-29-examples_to_connect_dbs_in_python.html#long-time-query",
    "title": "Connect databses in Python",
    "section": "Long time query",
    "text": "Long time query\n\n\nCode\nquery_long_time=\"\"\"\nomit\n\"\"\";\n\n\n\n\nCode\nstart=time.perf_counter()\npd.read_gbq(query_long_time, os.environ['BQ_PROJECT_NAME'])\nprint(time.perf_counter()-start)\n\n\n209.955542535\n\n\n\n\nCode\nstart=time.perf_counter()\npd.read_gbq(query_long_time, os.environ['BQ_PROJECT_NAME'], use_bqstorage_api=True)\nprint(time.perf_counter()-start)\n\n\n10.184412958999985"
  },
  {
    "objectID": "posts/2021-07-29-examples_to_connect_dbs_in_python.html#cf-long-time-query-in-redshift",
    "href": "posts/2021-07-29-examples_to_connect_dbs_in_python.html#cf-long-time-query-in-redshift",
    "title": "Connect databses in Python",
    "section": "cf) Long time query in Redshift",
    "text": "cf) Long time query in Redshift\n\n\nCode\nquery=\"\"\"\nomit\n\"\"\";\n\n\n\n\nCode\nstart=time.perf_counter()\nsql(query)\nprint(time.perf_counter()-start)\n\n\n49.52570845600002"
  },
  {
    "objectID": "posts/stepci.html",
    "href": "posts/stepci.html",
    "title": "stepciのworkflow.yamlの上手かもしれない書き方",
    "section": "",
    "text": "Introduction\nREST APIのテストを作成してCI/CDで動かしたい. 以前紹介したschemathesisはopenapi.jsonがある場合にそれを利用して上手にテストしてくれるパッケージだった. 今回はstepciを試してみた. 実はstepciにもopenapiのintegration機能がありschemathesisより先に存在を知って一度試したことがあるがopneapiを利用するという形では思い通りのテストができなかったので一度断念した. ではなぜまたstepciを試したのかというとopenapi.jsonを使わないという方針が\"上\"によって決められたからである. APIの仕様はopenapiに沿って作られれば色々便利なことがあるがきちんと作るのはなかなか大変である. 実際のところは引き続きfastAPIを使うのでopenapi.jsonは存在するのだがそれは仕様ではないので仕様に沿ったテストを別途実施したいということだ. 当面はスプレッドシートで仕様が管理されるということなので我々はその仕様からjsonを生成してAPIのテストをするという話になった. jsonをいくつか用意してrequestを投げてstatus codeとresponseをチェックするだけなので自前で用意するより先人の知恵に頼ってgoogleで検索してみるとpostman+newmanが結果にでてくるので試してみたがPostmanが仕事のケースに合わなかったので保留した. Postmanが合わなかった部分はテストしたいPOST methodのrequest bodyの形が複雑なのでGUIの恩恵を受けられずraw dataとしてjsonをそのまま貼り付けなければならないこと, テストをjavascriptで書かなければならないことである. そこで再調査したとこと再びstepciに行き着いたので試してみた.\n\n\nStepci\n結論から言えばjsonを用意してrequestを行いresponseを検証するということはstepciで十分可能だった. しかしちょっと困った点はテストの項目1つに対し複数のrequest bodyを用意してfor loopのようなことがしたい場合にどうやって書くかがわからなかったことだ. data/以下にhoge1.json, hoge2.json …と用意してテストケースを分類してテストを行いたいと考えていたのだがloopに当たる機能はstepciにはなさそうで下のexample1のように助長になってしまう. なのでどうしたものかと思っていたがyamlの構文にアンカーやエイリアスがあるのでそれが使えるかもしれないと試してみたのがexample2である. この構文はstepciでも使えたので若干記述が楽になった. 更に調べてみるとstepci runnerというものもありこちらはjavascript(typescript?)でworkflowが作れるようでloopしたい場合はこちらの方が便利かもしれない. 残念ながらdocmentは貧弱なのでソースコードを読む必要がある.\nversion: \"1.1\"\nname: Demo of API tests\nenv:\n  host: http://foo\ncommon: &common\n  http:\n    url: ${{env.host}}/bar\n    method: POST\n    check:\n      status: 200\n\ntests:\n  example1:\n    steps:\n      - name: GET request(example)\n        http:\n          url: https://example.com\n          method: GET\n          check:\n            selectors:\n              title: Example Domain\n      - name: GET\n        http:\n          url: ${{env.host}}/healthcheck\n          method: GET\n          check:\n            status: 200\n      - name: POST request\n        http:\n          url: ${{env.host}}/var\n          method: POST\n          body:\n            file: data/hoge1.json\n          check:\n            status: 200\n      - name: POST request\n        http:\n          url: ${{env.host}}/var\n          method: POST\n          body:\n            file: data/hoge2.json\n          check:\n            status: 200\n  example2:\n    steps:\n      - &lt;&lt;:: *common\n        name: 1\n        body:\n          file: data/hoge1.json\n      - &lt;&lt;:: *common\n        name: 2\n        body:\n          file: data/hoge2.json  \n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/fastapi.html",
    "href": "posts/fastapi.html",
    "title": "uvicorn vs gunicorn",
    "section": "",
    "text": "筆者が現在所属している株式会社FLINRTERSは2024年1月で10周年を迎え, その記念企画として全社員でブログリレーを行っている. この記事は133日間ブログを書き続けるチャレンジの105日目の記事である(1日目の記事はこちら). 当サイトは筆者の個人サイトとして公開しているが今回の記事に限り会社の企画の一環として作成した.\n筆者はDeep Laerningを利用した機械学習サービスの開発に2年程参加している. 機械学習サービスはコンテナ化されたREST APIとして開発を行いAWSのECSを利用してデプロイしている. コンテナはFastAPIを利用してREST APIを開発している. FastAPIはpythonで開発できるwebフレームワークで筆者が開発に参加した時に既に採用されていて現在も使用している. 以下で筆者がFastAPIを利用する際にハマった点を紹介する. ここで考えたいのは複数のリクエストを捌くためにREST APIの構成をどのようにするかという問題である. APIを動かすサーバーの構成やアプリケーション自身の性質によって選択肢は様々あるがここでは以下を考える:\n\nuvicorn vs gunicorn\nworkers vs container replication\n\nよく考えれば(FastAPIのドキュメントをきちんと読めば)悩むことはないのだが迷走してしまった.\n\n\nFastAPIをサーバーとして起動する場合uvicorn, hypercorn, daphneそしてgunicornを選択できる. 例えばuvicornの場合は\nuvicorn main:app --host 0.0.0.0 --port 80  \ngunicornの場合は\ngunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:80\n等である. さてuviconrのドキュメントを読むと以下の様な記述がある:\n\nFor production deployments we recommend using gunicorn with the uvicorn worker class.\n\n一方でFastAPIのドキュメントには以下のような説明がある.\n\nGunicorn is mainly an application server using the WSGI standard. That means that Gunicorn can serve applications like Flask and Django. Gunicorn by itself is not compatible with FastAPI, as FastAPI uses the newest ASGI standard.\nBut Gunicorn supports working as a process manager and allowing users to tell it which specific worker process class to use. Then Gunicorn would start one or more worker processes using that class.\nAnd Uvicorn has a Gunicorn-compatible worker class.\nUsing that combination, Gunicorn would act as a process manager, listening on the port and the IP. And it would transmit the communication to the worker processes running the Uvicorn class.\nAnd then the Gunicorn-compatible Uvicorn worker class would be in charge of converting the data sent by Gunicorn to the ASGI standard for FastAPI to use it.\n\nWSGI(Web Server Gateway Interface)は同期的なAPIの規格, ASGI（Asynchronous Server Gateway Interface)は非同期的なAPIの規格という意味である. (同期/非同期の違いと並列/並行の違いもFastAPIのドキュメントで説明されているので一読するとよい.) ドキュメントによればgunicornはWSGIで同期的, uvicorn, hypercornそしてdaphneは非同期的ということだそうだ. uvicornもFastAPIもmultiple workersでAPIを起動したい場合はgunicornによる起動を推奨している. しかしAPIをコンテナとして開発しkubernetesやECSのようなコンテナをスケールできるクラウドサービスを利用している場合はsingle processとしてコンテナを作りクラスターレベルでコンテナを複製するやり方を推奨している. プロジェクトではGPUを使い, ちょうどよいAWSのインスタンスはGPUが1つである. GPUが1つなので1つのコンテナに同時に複数のリクエストがきた場合1つのGPUを取り合ってしまうため(全体の処理時間はほとんど変わらないが)リクエストあたりの処理時間が伸びてしまう. よって1つのコンテナでは1つずつリクエストを同期的なAPIを選択すれば良いからgunicornで1つのworkerにすれば良いと考えた.\n\n\n\nところが実際に負荷テストをしてみると次の様な結果になった:\n\nConcurrency=1で2リクエスト\n\nhey -n 2 -c 1 -t 2000 -m POST -D ./test_1.json -H 'accept: application/json'  -H 'Content-Type: application/json' $endpoint\n\nSummary:\n  Total:    1334.9580 secs\n  Slowest:  677.1068 secs\n  Fastest:  657.8511 secs\n  Average:  667.4790 secs\n  Requests/sec: 0.0015\n\n  Total data:   18864 bytes\n  Size/request: 9432 bytes\n\nResponse time histogram:\n  657.851 [1]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  659.777 [0]   |\n  661.702 [0]   |\n  663.628 [0]   |\n  665.553 [0]   |\n  667.479 [0]   |\n  669.405 [0]   |\n  671.330 [0]   |\n  673.256 [0]   |\n  675.181 [0]   |\n  677.107 [1]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n\n\nLatency distribution:\n  10% in 677.1068 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0006 secs, 657.8511 secs, 677.1068 secs\n  DNS-lookup:   0.0004 secs, 0.0000 secs, 0.0008 secs\n  req write:    0.0001 secs, 0.0000 secs, 0.0001 secs\n  resp wait:    667.4661 secs, 657.8509 secs, 677.0813 secs\n  resp read:    0.0121 secs, 0.0002 secs, 0.0241 secs\n\nStatus code distribution:\n  [200] 2 responses\n\nConcurrency=2で2リクエスト\n\nhey -n 2 -c 2 -t 2000 -m POST -D ./test_1.json -H 'accept: application/json'  -H 'Content-Type: application/json' $endpoint\n\nSummary:\n  Total:    1349.7194 secs\n  Slowest:  1349.7193 secs\n  Fastest:  1349.6560 secs\n  Average:  1349.6877 secs\n  Requests/sec: 0.0015\n\n  Total data:   18860 bytes\n  Size/request: 9430 bytes\n\nResponse time histogram:\n  1349.656 [1]  |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1349.662 [0]  |\n  1349.669 [0]  |\n  1349.675 [0]  |\n  1349.681 [0]  |\n  1349.688 [0]  |\n  1349.694 [0]  |\n  1349.700 [0]  |\n  1349.707 [0]  |\n  1349.713 [0]  |\n  1349.719 [1]  |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n\n\nLatency distribution:\n  10% in 1349.7193 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0012 secs, 1349.6560 secs, 1349.7193 secs\n  DNS-lookup:   0.0007 secs, 0.0007 secs, 0.0007 secs\n  req write:    0.0001 secs, 0.0001 secs, 0.0001 secs\n  resp wait:    1349.6736 secs, 1349.6293 secs, 1349.7178 secs\n  resp read:    0.0127 secs, 0.0001 secs, 0.0253 secs\n\nStatus code distribution:\n  [200] 2 responses\nここでheyは並行リクエストを行うためのパッケージである. このように1つずつのリクエストは660秒程度でレスポンスされるが同時に2リクエストされると1349秒程度となってしまった. totalのレスポンス時間はほとんど変わらないが各レスポンスでは1つずつリクエストをした場合の倍程度の時間がかかっている. この挙動はgunicornで起動しているのに非同期的な挙動をしているということだ. どうなっているんだろうか？\n\n\n\n結論から言うとFastAPIをgunicornで動かす時gunicornはuvicorn workerのプロセスマネージャーとして動作し全体としては非同期的なAPIとなる. 同期的なAPIとなる場合はFlaskやDjangoをgunicornで動かした場合である.\n\n\n\n以下では検証用コードを用意して検証する.\n\ndocker-compose.yml\n\n\nversion: \"3.9\"  \nservices:\n  fastapi-uvicorn:\n    build:\n      context: fastapi\n      dockerfile: Dockerfile\n    environment:\n      - MODEL=wait\n      - WAITING_TIME=1\n    tty: true\n    healthcheck:\n      test: curl http://localhost:8000/healthcheck\n    command: uvicorn --workers ${WORKERS:-1} --timeout-keep-alive 60 --host 0.0.0.0 --port 8000 src.main:app\n\n  fastapi-gunicorn:\n    build:\n      context: fastapi\n      dockerfile: Dockerfile\n    environment:\n      - MODEL=wait\n      - WAITING_TIME=1      \n    tty: true\n    healthcheck:\n      test: curl http://localhost:8000/healthcheck\n    command: gunicorn -w ${WORKERS:-1} -t 60 --keep-alive=60 --bind=0000:8000 -k uvicorn.workers.UvicornWorker src.main:app\n\n  flask:\n    build:\n      context: flask\n      dockerfile: Dockerfile\n    environment:\n      - WAITING_TIME=1      \n    tty: true\n    command: gunicorn -w ${WORKERS:-1} -b 0.0.0.0:8000 app:app\n\n  client:\n    build:\n      context: client\n      dockerfile: Dockerfile\n    volumes:\n      - ./client/src:/workspace/\n    tty: true\n\nnetworks:\n  app-net:\n    driver: bridge    \nserver用にFastAPIをuvicornとgunicornでそれぞれ起動したコンテナとFlaskをgunicornで起動したコンテナを用意した. どのエンドポイントも1秒待つだけのものである. 以下ではclientに接続してserverへリクエストする.\n\nmain.py\nこのスクリプトではそれぞれのエンドポイントにそれぞれ非同期的に10リクエストを行う. FastAPIではさらに内部で同期的な処理(sync)と非同期的な処理(async)を用意した.\n\nimport httpx as requests\nfrom asyncio import run, gather\n\nfrom functools import wraps\nimport time\n\n\ndef stop_watch(func) :\n    @wraps(func)\n    def wrapper(*args, **kargs) :\n        start = time.time()\n        result = func(*args,**kargs)\n        elapsed_time =  time.time() - start\n        print(f\"{func.__name__} is {elapsed_time} sec\")\n        return result\n    return wrapper\n\nn=10\n\nurls1 = [\"http://fastapi-uvicorn:8000/sync\"] * n\nurls2 = [\"http://fastapi-uvicorn:8000/async\"] * n\nurls3 = [\"http://fastapi-gunicorn:8000/sync\"] * n\nurls4 = [\"http://fastapi-gunicorn:8000/async\"] * n\nurls5 = [\"http://flask:8000/wait\"] * n\n\n@stop_watch\ndef req(url):\n    return requests.get(url).json()[\"wait\"]\n\ndef sync_func(urls):\n    res=sorted([float(req(u)) for u in urls])\n\ndef main(urls):\n    start = time.time()\n    sync_func(urls)\n    elapsed_time =  time.time() - start\n    print(f\"tolal time: {elapsed_time} sec.\")\n\n# print(\"sync\")\n# main(urls1)\n# main(urls2)\n# main(urls3)\n# main(urls4)\n\nasync def async_request(client,url):\n    start = time.time()\n    r = await client.get(url)\n    j = r.json()\n    elapsed_time =  time.time() - start\n    #return float(j[\"wait\"])\n    return elapsed_time\n\nasync def async_func(urls):\n    async with requests.AsyncClient(timeout=requests.Timeout(50.0, read=100.0)) as client:\n        tasks = [async_request(client,u) for u in urls]\n        res=await gather(*tasks, return_exceptions=True)\n        print(sorted(res))\n\n\ndef main2(urls):\n    print(urls[0])\n    start = time.time()\n    run(async_func(urls))\n    elapsed_time =  time.time() - start\n    print(f\"total time: {elapsed_time} sec.\")\n    print(\"\")\n\nprint(\"\")\nprint(\"async\")\nmain2(urls1)\nmain2(urls2)\nmain2(urls3)\nmain2(urls4)\nmain2(urls5)\n\nmain.pyの実行結果\n\n&gt;python main.py\n\nasync\nhttp://fastapi-uvicorn:8000/sync\n[1.024996042251587, 1.026745080947876, 1.0276827812194824, 1.0283920764923096, 1.0295100212097168, 1.0298545360565186, 1.0308914184570312, 1.0322017669677734, 1.0322880744934082, 1.0322985649108887]\ntotal time: 1.0637059211730957 sec.\n\nhttp://fastapi-uvicorn:8000/async\n[1.0175724029541016, 1.018122911453247, 1.0189146995544434, 1.0196821689605713, 1.020909309387207, 1.0213782787322998, 1.0219099521636963, 1.0230631828308105, 1.0235424041748047, 1.0240747928619385]\ntotal time: 1.0593938827514648 sec.\n\nhttp://fastapi-gunicorn:8000/sync\n[1.0269830226898193, 1.027055263519287, 1.0285744667053223, 1.0295593738555908, 1.0305025577545166, 1.0309679508209229, 1.03269624710083, 1.0332932472229004, 1.0338554382324219, 1.0339922904968262]\ntotal time: 1.0705046653747559 sec.\n\nhttp://fastapi-gunicorn:8000/async\n[1.0173935890197754, 1.017953872680664, 1.0187129974365234, 1.0193700790405273, 1.020677089691162, 1.021491527557373, 1.0224878787994385, 1.0230729579925537, 1.0231189727783203, 1.0231926441192627]\ntotal time: 1.060159683227539 sec.\n\nhttp://flask:8000/wait\n[1.0182826519012451, 2.021609306335449, 3.0245327949523926, 4.027919054031372, 5.02778172492981, 6.030719518661499, 7.033880949020386, 8.036886215209961, 9.039915323257446, 10.04302167892456]\ntotal time: 10.079250574111938 sec.\nFastAPIにリクエストをするとuvicorn, gunicornの違いや内部コードが同期/非同期に関わらず1秒程度でレスポンスされることがわかる. サーバー側に十分な処理能力があるのでworkerが1つでも全体の処理時間も1秒程度である. 一方Flaskにリクエストすると同期的にリクエストが処理されるので1番目のリクエストは1秒で返ってくるが10番目のリクエストは処理まで待たされるためレスポンスに10秒程度かかっていることがわかる.\n\n\n\nFastAPI内部でのdefとasync defの使い分けにあるように内部で更に非同期処理を行っている場合はパフォーマンスの最適化ができる. ここでは大量のリクエストを行いパフォーマンスの違いを確認する. 各エンドポイントに1000リクエストを並行で行うと同期処理の場合はどんどんレスポンスが遅くなるのに対し非同期処理の場合はほとんどレスポンスが遅くならない:\n\n\nroot@6fbcaa856ca9:/workspace# hey -n 1000 -c 1000 http://fastapi-uvicorn:8000/sync\n\nSummary:\n  Total:    9.1911 secs\n  Slowest:  9.1805 secs\n  Fastest:  1.0084 secs\n  Average:  3.5174 secs\n  Requests/sec: 108.8007\n\n  Total data:   28754 bytes\n  Size/request: 28 bytes\n\nResponse time histogram:\n  1.008 [1] |\n  1.826 [199]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  2.643 [200]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  3.460 [186]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  4.277 [157]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  5.094 [28]    |■■■■■■\n  5.912 [75]    |■■■■■■■■■■■■■■■\n  6.729 [50]    |■■■■■■■■■■\n  7.546 [40]    |■■■■■■■■\n  8.363 [40]    |■■■■■■■■\n  9.180 [24]    |■■■■■\n\n\nLatency distribution:\n  10% in 1.0897 secs\n  25% in 2.0721 secs\n  50% in 3.1144 secs\n  75% in 5.0093 secs\n  90% in 7.1048 secs\n  95% in 8.1422 secs\n  99% in 9.1499 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0326 secs, 1.0084 secs, 9.1805 secs\n  DNS-lookup:   0.0281 secs, 0.0000 secs, 0.0755 secs\n  req write:    0.0021 secs, 0.0000 secs, 0.0567 secs\n  resp wait:    3.4776 secs, 1.0031 secs, 9.1080 secs\n  resp read:    0.0002 secs, 0.0000 secs, 0.0023 secs\n\nStatus code distribution:\n  [200] 1000 responses\n\n\n\nroot@6fbcaa856ca9:/workspace# hey -n 1000 -c 1000 http://fastapi-uvicorn:8000/async\n\nSummary:\n  Total:    1.2514 secs\n  Slowest:  1.2316 secs\n  Fastest:  1.0523 secs\n  Average:  1.1256 secs\n  Requests/sec: 799.1115\n\n  Total data:   28714 bytes\n  Size/request: 28 bytes\n\nResponse time histogram:\n  1.052 [1] |\n  1.070 [51]    |■■■■■■■■■■■■\n  1.088 [166]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.106 [160]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.124 [157]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.142 [129]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.160 [93]    |■■■■■■■■■■■■■■■■■■■■■■\n  1.178 [106]   |■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.196 [85]    |■■■■■■■■■■■■■■■■■■■■\n  1.214 [50]    |■■■■■■■■■■■■\n  1.232 [2] |\n\n\nLatency distribution:\n  10% in 1.0765 secs\n  25% in 1.0920 secs\n  50% in 1.1195 secs\n  75% in 1.1580 secs\n  90% in 1.1851 secs\n  95% in 1.1965 secs\n  99% in 1.2086 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0618 secs, 1.0523 secs, 1.2316 secs\n  DNS-lookup:   0.0344 secs, 0.0005 secs, 0.0650 secs\n  req write:    0.0031 secs, 0.0000 secs, 0.0487 secs\n  resp wait:    1.0588 secs, 1.0023 secs, 1.1469 secs\n  resp read:    0.0001 secs, 0.0000 secs, 0.0007 secs\n\nStatus code distribution:\n  [200] 1000 responses\n\n\n\nroot@6fbcaa856ca9:/workspace# hey -n 1000 -c 1000 http://fastapi-gunicorn:8000/sync\n\nSummary:\n  Total:    7.0586 secs\n  Slowest:  7.0112 secs\n  Fastest:  1.0307 secs\n  Average:  3.2303 secs\n  Requests/sec: 141.6702\n\n  Total data:   28739 bytes\n  Size/request: 28 bytes\n\nResponse time histogram:\n  1.031 [1] |\n  1.629 [199]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  2.227 [200]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  2.825 [0] |\n  3.423 [200]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  4.021 [40]    |■■■■■■■■\n  4.619 [124]   |■■■■■■■■■■■■■■■■■■■■■■■■■\n  5.217 [150]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  5.815 [0] |\n  6.413 [82]    |■■■■■■■■■■■■■■■■\n  7.011 [4] |■\n\n\nLatency distribution:\n  10% in 1.1207 secs\n  25% in 2.0946 secs\n  50% in 3.1330 secs\n  75% in 4.1489 secs\n  90% in 5.1593 secs\n  95% in 6.1270 secs\n  99% in 6.1581 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0530 secs, 1.0307 secs, 7.0112 secs\n  DNS-lookup:   0.0285 secs, 0.0000 secs, 0.0688 secs\n  req write:    0.0045 secs, 0.0000 secs, 0.0916 secs\n  resp wait:    3.1651 secs, 1.0026 secs, 6.9203 secs\n  resp read:    0.0002 secs, 0.0000 secs, 0.0021 secs\n\nStatus code distribution:\n  [200] 1000 responses\n\n\n\nroot@6fbcaa856ca9:/workspace# hey -n 1000 -c 1000 http://fastapi-gunicorn:8000/async\n\nSummary:\n  Total:    1.2252 secs\n  Slowest:  1.2068 secs\n  Fastest:  1.0091 secs\n  Average:  1.0905 secs\n  Requests/sec: 816.1771\n\n  Total data:   28749 bytes\n  Size/request: 28 bytes\n\nResponse time histogram:\n  1.009 [1] |\n  1.029 [20]    |■■■\n  1.049 [115]   |■■■■■■■■■■■■■■■■■■■\n  1.068 [247]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.088 [165]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.108 [125]   |■■■■■■■■■■■■■■■■■■■■\n  1.128 [123]   |■■■■■■■■■■■■■■■■■■■■\n  1.147 [108]   |■■■■■■■■■■■■■■■■■\n  1.167 [36]    |■■■■■■\n  1.187 [52]    |■■■■■■■■\n  1.207 [8] |■\n\n\nLatency distribution:\n  10% in 1.0466 secs\n  25% in 1.0568 secs\n  50% in 1.0803 secs\n  75% in 1.1210 secs\n  90% in 1.1463 secs\n  95% in 1.1695 secs\n  99% in 1.1858 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0351 secs, 1.0091 secs, 1.2068 secs\n  DNS-lookup:   0.0257 secs, 0.0000 secs, 0.0862 secs\n  req write:    0.0037 secs, 0.0000 secs, 0.0570 secs\n  resp wait:    1.0453 secs, 1.0023 secs, 1.1422 secs\n  resp read:    0.0001 secs, 0.0000 secs, 0.0012 secs\n\nStatus code distribution:\n  [200] 1000 responses"
  },
  {
    "objectID": "posts/fastapi.html#uvicorn-vs-gunicorn-1",
    "href": "posts/fastapi.html#uvicorn-vs-gunicorn-1",
    "title": "uvicorn vs gunicorn",
    "section": "",
    "text": "FastAPIをサーバーとして起動する場合uvicorn, hypercorn, daphneそしてgunicornを選択できる. 例えばuvicornの場合は\nuvicorn main:app --host 0.0.0.0 --port 80  \ngunicornの場合は\ngunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:80\n等である. さてuviconrのドキュメントを読むと以下の様な記述がある:\n\nFor production deployments we recommend using gunicorn with the uvicorn worker class.\n\n一方でFastAPIのドキュメントには以下のような説明がある.\n\nGunicorn is mainly an application server using the WSGI standard. That means that Gunicorn can serve applications like Flask and Django. Gunicorn by itself is not compatible with FastAPI, as FastAPI uses the newest ASGI standard.\nBut Gunicorn supports working as a process manager and allowing users to tell it which specific worker process class to use. Then Gunicorn would start one or more worker processes using that class.\nAnd Uvicorn has a Gunicorn-compatible worker class.\nUsing that combination, Gunicorn would act as a process manager, listening on the port and the IP. And it would transmit the communication to the worker processes running the Uvicorn class.\nAnd then the Gunicorn-compatible Uvicorn worker class would be in charge of converting the data sent by Gunicorn to the ASGI standard for FastAPI to use it.\n\nWSGI(Web Server Gateway Interface)は同期的なAPIの規格, ASGI（Asynchronous Server Gateway Interface)は非同期的なAPIの規格という意味である. (同期/非同期の違いと並列/並行の違いもFastAPIのドキュメントで説明されているので一読するとよい.) ドキュメントによればgunicornはWSGIで同期的, uvicorn, hypercornそしてdaphneは非同期的ということだそうだ. uvicornもFastAPIもmultiple workersでAPIを起動したい場合はgunicornによる起動を推奨している. しかしAPIをコンテナとして開発しkubernetesやECSのようなコンテナをスケールできるクラウドサービスを利用している場合はsingle processとしてコンテナを作りクラスターレベルでコンテナを複製するやり方を推奨している. プロジェクトではGPUを使い, ちょうどよいAWSのインスタンスはGPUが1つである. GPUが1つなので1つのコンテナに同時に複数のリクエストがきた場合1つのGPUを取り合ってしまうため(全体の処理時間はほとんど変わらないが)リクエストあたりの処理時間が伸びてしまう. よって1つのコンテナでは1つずつリクエストを同期的なAPIを選択すれば良いからgunicornで1つのworkerにすれば良いと考えた."
  },
  {
    "objectID": "posts/fastapi.html#実際の挙動",
    "href": "posts/fastapi.html#実際の挙動",
    "title": "uvicorn vs gunicorn",
    "section": "",
    "text": "ところが実際に負荷テストをしてみると次の様な結果になった:\n\nConcurrency=1で2リクエスト\n\nhey -n 2 -c 1 -t 2000 -m POST -D ./test_1.json -H 'accept: application/json'  -H 'Content-Type: application/json' $endpoint\n\nSummary:\n  Total:    1334.9580 secs\n  Slowest:  677.1068 secs\n  Fastest:  657.8511 secs\n  Average:  667.4790 secs\n  Requests/sec: 0.0015\n\n  Total data:   18864 bytes\n  Size/request: 9432 bytes\n\nResponse time histogram:\n  657.851 [1]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  659.777 [0]   |\n  661.702 [0]   |\n  663.628 [0]   |\n  665.553 [0]   |\n  667.479 [0]   |\n  669.405 [0]   |\n  671.330 [0]   |\n  673.256 [0]   |\n  675.181 [0]   |\n  677.107 [1]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n\n\nLatency distribution:\n  10% in 677.1068 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0006 secs, 657.8511 secs, 677.1068 secs\n  DNS-lookup:   0.0004 secs, 0.0000 secs, 0.0008 secs\n  req write:    0.0001 secs, 0.0000 secs, 0.0001 secs\n  resp wait:    667.4661 secs, 657.8509 secs, 677.0813 secs\n  resp read:    0.0121 secs, 0.0002 secs, 0.0241 secs\n\nStatus code distribution:\n  [200] 2 responses\n\nConcurrency=2で2リクエスト\n\nhey -n 2 -c 2 -t 2000 -m POST -D ./test_1.json -H 'accept: application/json'  -H 'Content-Type: application/json' $endpoint\n\nSummary:\n  Total:    1349.7194 secs\n  Slowest:  1349.7193 secs\n  Fastest:  1349.6560 secs\n  Average:  1349.6877 secs\n  Requests/sec: 0.0015\n\n  Total data:   18860 bytes\n  Size/request: 9430 bytes\n\nResponse time histogram:\n  1349.656 [1]  |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1349.662 [0]  |\n  1349.669 [0]  |\n  1349.675 [0]  |\n  1349.681 [0]  |\n  1349.688 [0]  |\n  1349.694 [0]  |\n  1349.700 [0]  |\n  1349.707 [0]  |\n  1349.713 [0]  |\n  1349.719 [1]  |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n\n\nLatency distribution:\n  10% in 1349.7193 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n  0% in 0.0000 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0012 secs, 1349.6560 secs, 1349.7193 secs\n  DNS-lookup:   0.0007 secs, 0.0007 secs, 0.0007 secs\n  req write:    0.0001 secs, 0.0001 secs, 0.0001 secs\n  resp wait:    1349.6736 secs, 1349.6293 secs, 1349.7178 secs\n  resp read:    0.0127 secs, 0.0001 secs, 0.0253 secs\n\nStatus code distribution:\n  [200] 2 responses\nここでheyは並行リクエストを行うためのパッケージである. このように1つずつのリクエストは660秒程度でレスポンスされるが同時に2リクエストされると1349秒程度となってしまった. totalのレスポンス時間はほとんど変わらないが各レスポンスでは1つずつリクエストをした場合の倍程度の時間がかかっている. この挙動はgunicornで起動しているのに非同期的な挙動をしているということだ. どうなっているんだろうか？"
  },
  {
    "objectID": "posts/fastapi.html#答え",
    "href": "posts/fastapi.html#答え",
    "title": "uvicorn vs gunicorn",
    "section": "",
    "text": "結論から言うとFastAPIをgunicornで動かす時gunicornはuvicorn workerのプロセスマネージャーとして動作し全体としては非同期的なAPIとなる. 同期的なAPIとなる場合はFlaskやDjangoをgunicornで動かした場合である."
  },
  {
    "objectID": "posts/fastapi.html#検証",
    "href": "posts/fastapi.html#検証",
    "title": "uvicorn vs gunicorn",
    "section": "",
    "text": "以下では検証用コードを用意して検証する.\n\ndocker-compose.yml\n\n\nversion: \"3.9\"  \nservices:\n  fastapi-uvicorn:\n    build:\n      context: fastapi\n      dockerfile: Dockerfile\n    environment:\n      - MODEL=wait\n      - WAITING_TIME=1\n    tty: true\n    healthcheck:\n      test: curl http://localhost:8000/healthcheck\n    command: uvicorn --workers ${WORKERS:-1} --timeout-keep-alive 60 --host 0.0.0.0 --port 8000 src.main:app\n\n  fastapi-gunicorn:\n    build:\n      context: fastapi\n      dockerfile: Dockerfile\n    environment:\n      - MODEL=wait\n      - WAITING_TIME=1      \n    tty: true\n    healthcheck:\n      test: curl http://localhost:8000/healthcheck\n    command: gunicorn -w ${WORKERS:-1} -t 60 --keep-alive=60 --bind=0000:8000 -k uvicorn.workers.UvicornWorker src.main:app\n\n  flask:\n    build:\n      context: flask\n      dockerfile: Dockerfile\n    environment:\n      - WAITING_TIME=1      \n    tty: true\n    command: gunicorn -w ${WORKERS:-1} -b 0.0.0.0:8000 app:app\n\n  client:\n    build:\n      context: client\n      dockerfile: Dockerfile\n    volumes:\n      - ./client/src:/workspace/\n    tty: true\n\nnetworks:\n  app-net:\n    driver: bridge    \nserver用にFastAPIをuvicornとgunicornでそれぞれ起動したコンテナとFlaskをgunicornで起動したコンテナを用意した. どのエンドポイントも1秒待つだけのものである. 以下ではclientに接続してserverへリクエストする.\n\nmain.py\nこのスクリプトではそれぞれのエンドポイントにそれぞれ非同期的に10リクエストを行う. FastAPIではさらに内部で同期的な処理(sync)と非同期的な処理(async)を用意した.\n\nimport httpx as requests\nfrom asyncio import run, gather\n\nfrom functools import wraps\nimport time\n\n\ndef stop_watch(func) :\n    @wraps(func)\n    def wrapper(*args, **kargs) :\n        start = time.time()\n        result = func(*args,**kargs)\n        elapsed_time =  time.time() - start\n        print(f\"{func.__name__} is {elapsed_time} sec\")\n        return result\n    return wrapper\n\nn=10\n\nurls1 = [\"http://fastapi-uvicorn:8000/sync\"] * n\nurls2 = [\"http://fastapi-uvicorn:8000/async\"] * n\nurls3 = [\"http://fastapi-gunicorn:8000/sync\"] * n\nurls4 = [\"http://fastapi-gunicorn:8000/async\"] * n\nurls5 = [\"http://flask:8000/wait\"] * n\n\n@stop_watch\ndef req(url):\n    return requests.get(url).json()[\"wait\"]\n\ndef sync_func(urls):\n    res=sorted([float(req(u)) for u in urls])\n\ndef main(urls):\n    start = time.time()\n    sync_func(urls)\n    elapsed_time =  time.time() - start\n    print(f\"tolal time: {elapsed_time} sec.\")\n\n# print(\"sync\")\n# main(urls1)\n# main(urls2)\n# main(urls3)\n# main(urls4)\n\nasync def async_request(client,url):\n    start = time.time()\n    r = await client.get(url)\n    j = r.json()\n    elapsed_time =  time.time() - start\n    #return float(j[\"wait\"])\n    return elapsed_time\n\nasync def async_func(urls):\n    async with requests.AsyncClient(timeout=requests.Timeout(50.0, read=100.0)) as client:\n        tasks = [async_request(client,u) for u in urls]\n        res=await gather(*tasks, return_exceptions=True)\n        print(sorted(res))\n\n\ndef main2(urls):\n    print(urls[0])\n    start = time.time()\n    run(async_func(urls))\n    elapsed_time =  time.time() - start\n    print(f\"total time: {elapsed_time} sec.\")\n    print(\"\")\n\nprint(\"\")\nprint(\"async\")\nmain2(urls1)\nmain2(urls2)\nmain2(urls3)\nmain2(urls4)\nmain2(urls5)\n\nmain.pyの実行結果\n\n&gt;python main.py\n\nasync\nhttp://fastapi-uvicorn:8000/sync\n[1.024996042251587, 1.026745080947876, 1.0276827812194824, 1.0283920764923096, 1.0295100212097168, 1.0298545360565186, 1.0308914184570312, 1.0322017669677734, 1.0322880744934082, 1.0322985649108887]\ntotal time: 1.0637059211730957 sec.\n\nhttp://fastapi-uvicorn:8000/async\n[1.0175724029541016, 1.018122911453247, 1.0189146995544434, 1.0196821689605713, 1.020909309387207, 1.0213782787322998, 1.0219099521636963, 1.0230631828308105, 1.0235424041748047, 1.0240747928619385]\ntotal time: 1.0593938827514648 sec.\n\nhttp://fastapi-gunicorn:8000/sync\n[1.0269830226898193, 1.027055263519287, 1.0285744667053223, 1.0295593738555908, 1.0305025577545166, 1.0309679508209229, 1.03269624710083, 1.0332932472229004, 1.0338554382324219, 1.0339922904968262]\ntotal time: 1.0705046653747559 sec.\n\nhttp://fastapi-gunicorn:8000/async\n[1.0173935890197754, 1.017953872680664, 1.0187129974365234, 1.0193700790405273, 1.020677089691162, 1.021491527557373, 1.0224878787994385, 1.0230729579925537, 1.0231189727783203, 1.0231926441192627]\ntotal time: 1.060159683227539 sec.\n\nhttp://flask:8000/wait\n[1.0182826519012451, 2.021609306335449, 3.0245327949523926, 4.027919054031372, 5.02778172492981, 6.030719518661499, 7.033880949020386, 8.036886215209961, 9.039915323257446, 10.04302167892456]\ntotal time: 10.079250574111938 sec.\nFastAPIにリクエストをするとuvicorn, gunicornの違いや内部コードが同期/非同期に関わらず1秒程度でレスポンスされることがわかる. サーバー側に十分な処理能力があるのでworkerが1つでも全体の処理時間も1秒程度である. 一方Flaskにリクエストすると同期的にリクエストが処理されるので1番目のリクエストは1秒で返ってくるが10番目のリクエストは処理まで待たされるためレスポンスに10秒程度かかっていることがわかる."
  },
  {
    "objectID": "posts/fastapi.html#大量リクエストによるパフォーマンスの低下",
    "href": "posts/fastapi.html#大量リクエストによるパフォーマンスの低下",
    "title": "uvicorn vs gunicorn",
    "section": "",
    "text": "FastAPI内部でのdefとasync defの使い分けにあるように内部で更に非同期処理を行っている場合はパフォーマンスの最適化ができる. ここでは大量のリクエストを行いパフォーマンスの違いを確認する. 各エンドポイントに1000リクエストを並行で行うと同期処理の場合はどんどんレスポンスが遅くなるのに対し非同期処理の場合はほとんどレスポンスが遅くならない:\n\n\nroot@6fbcaa856ca9:/workspace# hey -n 1000 -c 1000 http://fastapi-uvicorn:8000/sync\n\nSummary:\n  Total:    9.1911 secs\n  Slowest:  9.1805 secs\n  Fastest:  1.0084 secs\n  Average:  3.5174 secs\n  Requests/sec: 108.8007\n\n  Total data:   28754 bytes\n  Size/request: 28 bytes\n\nResponse time histogram:\n  1.008 [1] |\n  1.826 [199]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  2.643 [200]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  3.460 [186]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  4.277 [157]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  5.094 [28]    |■■■■■■\n  5.912 [75]    |■■■■■■■■■■■■■■■\n  6.729 [50]    |■■■■■■■■■■\n  7.546 [40]    |■■■■■■■■\n  8.363 [40]    |■■■■■■■■\n  9.180 [24]    |■■■■■\n\n\nLatency distribution:\n  10% in 1.0897 secs\n  25% in 2.0721 secs\n  50% in 3.1144 secs\n  75% in 5.0093 secs\n  90% in 7.1048 secs\n  95% in 8.1422 secs\n  99% in 9.1499 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0326 secs, 1.0084 secs, 9.1805 secs\n  DNS-lookup:   0.0281 secs, 0.0000 secs, 0.0755 secs\n  req write:    0.0021 secs, 0.0000 secs, 0.0567 secs\n  resp wait:    3.4776 secs, 1.0031 secs, 9.1080 secs\n  resp read:    0.0002 secs, 0.0000 secs, 0.0023 secs\n\nStatus code distribution:\n  [200] 1000 responses\n\n\n\nroot@6fbcaa856ca9:/workspace# hey -n 1000 -c 1000 http://fastapi-uvicorn:8000/async\n\nSummary:\n  Total:    1.2514 secs\n  Slowest:  1.2316 secs\n  Fastest:  1.0523 secs\n  Average:  1.1256 secs\n  Requests/sec: 799.1115\n\n  Total data:   28714 bytes\n  Size/request: 28 bytes\n\nResponse time histogram:\n  1.052 [1] |\n  1.070 [51]    |■■■■■■■■■■■■\n  1.088 [166]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.106 [160]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.124 [157]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.142 [129]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.160 [93]    |■■■■■■■■■■■■■■■■■■■■■■\n  1.178 [106]   |■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.196 [85]    |■■■■■■■■■■■■■■■■■■■■\n  1.214 [50]    |■■■■■■■■■■■■\n  1.232 [2] |\n\n\nLatency distribution:\n  10% in 1.0765 secs\n  25% in 1.0920 secs\n  50% in 1.1195 secs\n  75% in 1.1580 secs\n  90% in 1.1851 secs\n  95% in 1.1965 secs\n  99% in 1.2086 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0618 secs, 1.0523 secs, 1.2316 secs\n  DNS-lookup:   0.0344 secs, 0.0005 secs, 0.0650 secs\n  req write:    0.0031 secs, 0.0000 secs, 0.0487 secs\n  resp wait:    1.0588 secs, 1.0023 secs, 1.1469 secs\n  resp read:    0.0001 secs, 0.0000 secs, 0.0007 secs\n\nStatus code distribution:\n  [200] 1000 responses\n\n\n\nroot@6fbcaa856ca9:/workspace# hey -n 1000 -c 1000 http://fastapi-gunicorn:8000/sync\n\nSummary:\n  Total:    7.0586 secs\n  Slowest:  7.0112 secs\n  Fastest:  1.0307 secs\n  Average:  3.2303 secs\n  Requests/sec: 141.6702\n\n  Total data:   28739 bytes\n  Size/request: 28 bytes\n\nResponse time histogram:\n  1.031 [1] |\n  1.629 [199]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  2.227 [200]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  2.825 [0] |\n  3.423 [200]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  4.021 [40]    |■■■■■■■■\n  4.619 [124]   |■■■■■■■■■■■■■■■■■■■■■■■■■\n  5.217 [150]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  5.815 [0] |\n  6.413 [82]    |■■■■■■■■■■■■■■■■\n  7.011 [4] |■\n\n\nLatency distribution:\n  10% in 1.1207 secs\n  25% in 2.0946 secs\n  50% in 3.1330 secs\n  75% in 4.1489 secs\n  90% in 5.1593 secs\n  95% in 6.1270 secs\n  99% in 6.1581 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0530 secs, 1.0307 secs, 7.0112 secs\n  DNS-lookup:   0.0285 secs, 0.0000 secs, 0.0688 secs\n  req write:    0.0045 secs, 0.0000 secs, 0.0916 secs\n  resp wait:    3.1651 secs, 1.0026 secs, 6.9203 secs\n  resp read:    0.0002 secs, 0.0000 secs, 0.0021 secs\n\nStatus code distribution:\n  [200] 1000 responses\n\n\n\nroot@6fbcaa856ca9:/workspace# hey -n 1000 -c 1000 http://fastapi-gunicorn:8000/async\n\nSummary:\n  Total:    1.2252 secs\n  Slowest:  1.2068 secs\n  Fastest:  1.0091 secs\n  Average:  1.0905 secs\n  Requests/sec: 816.1771\n\n  Total data:   28749 bytes\n  Size/request: 28 bytes\n\nResponse time histogram:\n  1.009 [1] |\n  1.029 [20]    |■■■\n  1.049 [115]   |■■■■■■■■■■■■■■■■■■■\n  1.068 [247]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.088 [165]   |■■■■■■■■■■■■■■■■■■■■■■■■■■■\n  1.108 [125]   |■■■■■■■■■■■■■■■■■■■■\n  1.128 [123]   |■■■■■■■■■■■■■■■■■■■■\n  1.147 [108]   |■■■■■■■■■■■■■■■■■\n  1.167 [36]    |■■■■■■\n  1.187 [52]    |■■■■■■■■\n  1.207 [8] |■\n\n\nLatency distribution:\n  10% in 1.0466 secs\n  25% in 1.0568 secs\n  50% in 1.0803 secs\n  75% in 1.1210 secs\n  90% in 1.1463 secs\n  95% in 1.1695 secs\n  99% in 1.1858 secs\n\nDetails (average, fastest, slowest):\n  DNS+dialup:   0.0351 secs, 1.0091 secs, 1.2068 secs\n  DNS-lookup:   0.0257 secs, 0.0000 secs, 0.0862 secs\n  req write:    0.0037 secs, 0.0000 secs, 0.0570 secs\n  resp wait:    1.0453 secs, 1.0023 secs, 1.1422 secs\n  resp read:    0.0001 secs, 0.0000 secs, 0.0012 secs\n\nStatus code distribution:\n  [200] 1000 responses"
  },
  {
    "objectID": "posts/sagemaker.html",
    "href": "posts/sagemaker.html",
    "title": "Amazon Sagemakerの感想",
    "section": "",
    "text": "SagemakerとはAWSのクラウドサービスの1つで機械学習の機能を多数備えている. 今回仕事の都合でSagemakerの調査を行ったのでその感想を書く. Sagemeker自体は良く考えられた微妙なサービスだという感想を持った. 悪いサービスではなく良く考えられたサービスで感心したのだがそのコンセプトがわかりづらく利用者にも刺さりづらそうであったので勝手な視点で紹介してみる. どんなサービスであるかの説明と個人, チームとしての利用者の視点で解説する."
  },
  {
    "objectID": "posts/sagemaker.html#jupyter",
    "href": "posts/sagemaker.html#jupyter",
    "title": "Amazon Sagemakerの感想",
    "section": "jupyter",
    "text": "jupyter\n僕はSagemakerはjupyterを中心に機能提供するサービスであるという印象を持っていたがこれはひどい誤解であった. その機能のひとつとしてクラウド上にjupyterを立ち上げて利用することができるが全体からみるとこの機能はおまけみたいなものだ. 例えばjupyterの例ではスペックの良いマシンを利用して試行錯誤したい場合に高価なマシンを自前で用意するより時間あたりで借りる方が合理的である. notebookは共通で後ろのインスタンス(マシン)をその都度変更するという機能も備えているので自前でEC2インスタンスを立ち上げてjupyterを利用する場合より便利に利用できる. jupyterを利用している場合, 個人でもチームでもマシンのスペックや台数を柔軟に変更したい場合はこのサービスは便利だろう."
  },
  {
    "objectID": "posts/sagemaker.html#学習",
    "href": "posts/sagemaker.html#学習",
    "title": "Amazon Sagemakerの感想",
    "section": "学習",
    "text": "学習\njupyter機能は機械学習のモデル開発者や開発チームにとっては便利だが学習の際に微妙な点がある. notebookは立ち上げ時間で料金がかかるのでちょっと学習して試行錯誤する分には便利だが長時間の学習では学習が終了した場合にはモデルをどこかに保存してjupyterを停止したい. こんな場合にはモデルの保存処理を書いたり, 学習が終了したら通知したり等いろんな工夫でなんとかできるが工夫が必要な時点でやはりどこかおかしいし面倒だ. 学習では学習時間だけクラウドを利用してモデルの管理もクラウドで面倒を見てくれた方が楽でSagemakerにはその機能がある. チュートリアルはsagemakerのnotebookを利用しつつ学習はsagemaker上で更に別建てのインスタンスで学習しているので非常にわかりづらいがnotebookでは学習は行っていない. この際にはpythonのsagemakerライブラリを利用しているのでnotebook上で素直に学習する場合と勝手が違うのはそのためだ."
  },
  {
    "objectID": "posts/sagemaker.html#デプロイ",
    "href": "posts/sagemaker.html#デプロイ",
    "title": "Amazon Sagemakerの感想",
    "section": "デプロイ",
    "text": "デプロイ\n仕事で機械学習のモデル開発を行っている場合最終的にはユーザーにそのモデルを利用してもらう必要がある. もちろんその提供方法には無限のやり方がある. 個人レベルではnotebookやコードをgithub公開するというやり方でも良いかもしれないがチームやプロジェクトで最終的にサービスとして提供する場合はモデルをどこかのコンピュータ上に載せて利用可能なサービスとして公開すると言う形になるだろう. 例えばREST APIとしてサービスを提供する場合, 物によるが, 機械学習は軽量なサービスにならない場合がほとんどなのでインフラのスケールなども考慮する必要があり自前で行うにはハードルが高い. SageMakerはこの辺りも考えられていて推論エンドポイントを公開する機能がある."
  },
  {
    "objectID": "posts/sagemaker.html#mlops",
    "href": "posts/sagemaker.html#mlops",
    "title": "Amazon Sagemakerの感想",
    "section": "MLOps",
    "text": "MLOps\nこの辺りの事情が今回僕がSagemakerを調査した理由でもある. 僕は博死して以来機械学習エンジニア→データサイエンティスト→MLOpsエンジニア(現在)という変遷で仕事をしているが所謂モデル開発者の時には僕自身にサービスをREST APIとして公開する能力はなかったし自分の経験した範囲ではモデル開発者でクラウド上にサービスを公開までできる人はいなかった. 今はモデルの開発をせずサービスの提供業務を仕事としているがやはりこれらは別の専門領域でありプロジェクトの体制としても人やチームが専門別に別れがちである. 事実現在のプロジェクトではデータサイエンティストとエンジニアのチームが会社レベルで別れている. 組織が別れていると所謂コンウェイの法則に関連する組織間のコミュニケーションのマネジメントやエンジアリングの課題に直面する. 現職のケースでは僕が参加した当時はデータサイエンティストが機械学習モデルを開発しコードをgitlabに, モデルをS3に置く. そしてその後エンジニアがREST APIに整形して公開するという体制であった. この場合データサイエンティストのモデル開発期間に加えて開発したモデルの変更に追随するREST APIの変更を行う必要があり開発期間が伸びるという課題があった. モデルが変更されるとドキュメントやテスト, インフラ, 仕様など様々な理由でデータサイエンティストとエンジニア間でコミュニケーションが発生する. このコミュニケーションを楽にするという目的のための候補がSagemakerというわけである. SagemakerはMLOpsやプロジェクトで説明にされるように機械学習サービスのMLOpsの哲学がクラウドサービスという形で提供されているのだ. この視点でSagemakerを見てみるとAWSがMLOpsを良く考えた上で機械学習クラウドサービスを提供しているのが伝わるのだが, 恐らくこの目玉であるこの哲学がなかなかわかりづらいのが微妙な所だ. データサイエンティストからみると(少なくとも僕の当初の理解では)サイエンス上の魅力的な機能はほとんど無いのも微妙に見えてしまう. この意味でsagemakerは良く考えられた微妙なサービスというわけである."
  }
]